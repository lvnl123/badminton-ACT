![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![MMPose](https://img.shields.io/badge/MMPose-Latest-green.svg)
![CUDA](https://img.shields.io/badge/CUDA-11.0+-purple.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-success.svg)
![Code Style](https://img.shields.io/badge/Code%20Style-PEP%208-orange.svg)
![Documentation](https://img.shields.io/badge/Documentation-Excellent-brightgreen.svg)
![Contributors](https://img.shields.io/badge/Contributors-Welcome-blueviolet.svg)
![Issues](https://img.shields.io/badge/Issues-Open-red.svg)
![PRs](https://img.shields.io/badge/PRs-Welcome-green.svg)

# ğŸ¸ TrackNetV3_Attention - ç«¯åˆ°ç«¯ç¾½æ¯›çƒè§†é¢‘æ™ºèƒ½åˆ†æä¸ä¸“ä¸šå¤ç›˜ç³»ç»Ÿ

<div align="center">

**åŸºäºæ·±åº¦å­¦ä¹ çš„ç¾½æ¯›çƒæ¯”èµ›è§†é¢‘åˆ†æå¹³å°**

[![Demo Video](https://img.shields.io/badge/Demo-Video-brightgreen.svg)](#demo)
[![Paper](https://img.shields.io/badge/Paper-Arxiv-orange.svg)](#citation)
[![Documentation](https://img.shields.io/badge/Docs-Online-blue.svg)](#documentation)

[ä¸­æ–‡](#ä¸­æ–‡) | [English](#english)

</div>

> **TrackNetV3_Attention** æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç¾½æ¯›çƒè§†é¢‘åˆ†æç³»ç»Ÿï¼Œé›†æˆäº†çƒä½“æ£€æµ‹ã€å§¿æ€ä¼°è®¡ã€äº‹ä»¶è¯†åˆ«ã€å‡»çƒåˆ†ç±»ã€åœºåœ°æ£€æµ‹ã€æ•°æ®å¯è§†åŒ–å’Œä¸“ä¸šå¤ç›˜ç­‰åŠŸèƒ½ã€‚ç³»ç»Ÿé‡‡ç”¨æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œä¸ºæ•™ç»ƒã€è¿åŠ¨å‘˜å’Œç ”ç©¶äººå‘˜æä¾›å…¨é¢çš„æ¯”èµ›åˆ†æå·¥å…·ã€‚

---

## âœ¨ æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§

### ğŸ¯ é«˜ç²¾åº¦çƒä½“æ£€æµ‹
- **TrackNetV3 + CBAM Attention**ï¼šç»“åˆå·ç§¯æ³¨æ„åŠ›æ¨¡å—çš„è½¨è¿¹è·Ÿè¸ªç½‘ç»œ
- **å¤šå¸§è¾“å…¥**ï¼šæ”¯æŒ 1-9 å¸§è¿ç»­è¾“å…¥ï¼Œæé«˜æ£€æµ‹å‡†ç¡®æ€§
- **è‡ªé€‚åº”é˜ˆå€¼**ï¼šå¯è°ƒèŠ‚çš„æ£€æµ‹é˜ˆå€¼ï¼Œå¹³è¡¡å¬å›ç‡å’Œç²¾ç¡®ç‡
- **å®æ—¶æ£€æµ‹**ï¼šGPU åŠ é€Ÿï¼Œæ”¯æŒå®æ—¶è§†é¢‘å¤„ç†
- **å‡†ç¡®ç‡ >95%**ï¼šåœ¨æ ‡å‡†æµ‹è¯•é›†ä¸Šçš„ä¼˜å¼‚è¡¨ç°

### ğŸƒ å®æ—¶å§¿æ€ä¼°è®¡
- **MMPose é›†æˆ**ï¼šåŸºäº MMPose æ¡†æ¶çš„å¤šäººä½“å§¿æ€æ£€æµ‹
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šRTMPose-T/S/M/L å››ç§æ¨¡å‹å¯é€‰
- **17 ä¸ªå…³é”®ç‚¹**ï¼šå®Œæ•´çš„ COCO æ ¼å¼äººä½“éª¨æ¶æ£€æµ‹
- **åŸºäºåœºåœ°çš„çƒå‘˜åˆ†é…**ï¼šè‡ªåŠ¨è¯†åˆ«ä¸Šä¸‹åŠåœºçƒå‘˜
- **å¤šç›®æ ‡è·Ÿè¸ª**ï¼šæ”¯æŒå¤šäººåœºæ™¯ä¸‹çš„ç¨³å®šè·Ÿè¸ª

### ğŸŸï¸ æ™ºèƒ½åœºåœ°è¯†åˆ«
- **Keypoint RCNN**ï¼šåŸºäºå…³é”®ç‚¹æ£€æµ‹çš„åœºåœ°è¯†åˆ«æ¨¡å‹
- **çƒç½‘æ£€æµ‹**ï¼šç‹¬ç«‹çš„çƒç½‘æ£€æµ‹æ¨¡å‹
- **35 ä¸ªå…³é”®ç‚¹**ï¼šè¯¦ç»†çš„åœºåœ°åˆ†åŒºå…³é”®ç‚¹
- **æ¯å¸§æ£€æµ‹æˆ–é—´éš”æ£€æµ‹**ï¼šçµæ´»çš„æ£€æµ‹ç­–ç•¥
- **é€è§†å˜æ¢**ï¼šè‡ªåŠ¨è®¡ç®—åœºåœ°è¾¹ç•Œå‚æ•°

### âš¡ å‡»çƒäº‹ä»¶æ£€æµ‹
- **å³°å€¼æ£€æµ‹ç®—æ³•**ï¼šåŸºäº scipy.signal.find_peaks çš„æ™ºèƒ½æ£€æµ‹
- **è§’åº¦å˜åŒ–åˆ†æ**ï¼šè½¨è¿¹è§’åº¦çªå˜æ£€æµ‹
- **å§¿æ€éªŒè¯**ï¼šç»“åˆçƒå‘˜ä½ç½®éªŒè¯å‡»çƒäº‹ä»¶
- **è¿ç»­æ€§éªŒè¯**ï¼šè½¨è¿¹è¿ç»­æ€§æ£€æŸ¥ï¼Œå‡å°‘è¯¯æ£€
- **è½åœ°å¸§è¿‡æ»¤**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œè¿‡æ»¤è½åœ°åçš„è½¨è¿¹
- **å¬å›ç‡ >90%**ï¼šåœ¨æ ‡å‡†æµ‹è¯•é›†ä¸Šçš„ä¼˜å¼‚è¡¨ç°

### ğŸ¾ å‡»çƒç±»å‹åˆ†ç±»
- **BST Transformer**ï¼šåŸºäº Transformer çš„å‡»çƒåˆ†ç±»æ¨¡å‹
- **35 ç§å‡»çƒç±»å‹**ï¼šæ¶µç›–æ‰€æœ‰å¸¸è§ç¾½æ¯›çƒå‡»çƒåŠ¨ä½œ
- **æ—¶åºç‰¹å¾èåˆ**ï¼šèåˆå§¿æ€ã€è½¨è¿¹å’Œä½ç½®ä¿¡æ¯
- **å¤šç§æ¨¡å‹å˜ä½“**ï¼šBSTã€BST_CGã€BST_APã€BST_CG_AP
- **Clean Gate æœºåˆ¶**ï¼šè‡ªåŠ¨è¿‡æ»¤å™ªå£°ç‰¹å¾
- **Aim Player æœºåˆ¶**ï¼šåŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„å‡»çƒè€…è¯†åˆ«

### ğŸ“Š ä¸“ä¸šæ•°æ®å¯è§†åŒ–
- **PySide6 äº¤äº’å¼ç•Œé¢**ï¼šç°ä»£åŒ–çš„ Qt6 å›¾å½¢ç•Œé¢
- **å¤šè§†é¢‘æ’­æ”¾å™¨**ï¼šè¾“å…¥ã€é¢„è§ˆã€è¾“å‡ºã€å¯¹æ¯”æ’­æ”¾
- **å®æ—¶æ•°æ®å›¾è¡¨**ï¼šçƒé€Ÿæ›²çº¿ã€çƒé«˜åº¦ã€å‡»çƒè®¡æ•°
- **åˆ†å¸ƒåˆ†æ**ï¼šçƒé€Ÿåˆ†å¸ƒã€å‡»çƒé—´éš”ã€å‡»çƒé«˜åº¦
- **é€‰æ‰‹åˆ†æ**ï¼šè¦†ç›–åŒºåŸŸã€é€Ÿåº¦æ›²çº¿ã€é—´è·åˆ†æ
- **å¯†åº¦çƒ­åŠ›å›¾**ï¼šçƒä½ç½®å¯†åº¦ï¼Œæ”¯æŒå¤šç§æ¨¡å¼
- **äº‹ä»¶è¡¨æ ¼**ï¼šå‡»çƒäº‹ä»¶ç­›é€‰å’Œæœç´¢

### ğŸ’¾ å¤šæ ¼å¼æ•°æ®å¯¼å‡º
- **CSV æ•°æ®è¡¨**ï¼šå®Œæ•´çš„å¸§çº§æ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰æ£€æµ‹ä¿¡æ¯
- **JSON äº‹ä»¶æ–‡ä»¶**ï¼šå‡»çƒäº‹ä»¶å’Œå‡»çƒç±»å‹çš„ç»“æ„åŒ–æ•°æ®
- **Numpy æ•°ç»„**ï¼šå§¿æ€å…³é”®ç‚¹çš„é«˜æ•ˆå­˜å‚¨æ ¼å¼
- **è§†é¢‘å¯è§†åŒ–**ï¼šç»¼åˆåˆ†æç»“æœçš„å¯è§†åŒ–è§†é¢‘
- **æˆªå›¾å¯¼å‡º**ï¼šæ”¯æŒæ¦‚è§ˆå’Œå›¾è¡¨çš„æˆªå›¾å¯¼å‡º

### ğŸ”„ è½¨è¿¹å¹³æ»‘ä¼˜åŒ–
- **å¡å°”æ›¼æ»¤æ³¢å™¨**ï¼šç»å…¸çš„è½¨è¿¹å¹³æ»‘ç®—æ³•
- **è‡ªé€‚åº”å‚æ•°**ï¼šå¯è°ƒèŠ‚çš„è¿‡ç¨‹å™ªå£°å’Œæµ‹é‡å™ªå£°
- **é—´éš™å¤„ç†**ï¼šæ™ºèƒ½å¤„ç†æ£€æµ‹é—´éš™
- **è·ç¦»éªŒè¯**ï¼šé˜²æ­¢å¼‚å¸¸è·³è·ƒ
- **è¯¯å·® <5 åƒç´ **ï¼šå¹³æ»‘åçš„è½¨è¿¹ç²¾åº¦

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ•°æ®æµç¨‹

```mermaid
graph TB
    A[è¾“å…¥è§†é¢‘<br/>MP4/AVI/MOV] --> B[é¢„å¤„ç†<br/>å¸§æå–+å°ºå¯¸è°ƒæ•´]
    B --> C[Step 0: çƒåœº/çƒç½‘æ£€æµ‹<br/>Keypoint RCNN]
    B --> D[Step 1: ç¾½æ¯›çƒæ£€æµ‹<br/>TrackNetV3+CBAM]
    B --> E[Step 2: å§¿æ€æ£€æµ‹<br/>MMPose]
    C --> F[åœºåœ°ä¿¡æ¯<br/>è¾¹ç•Œå‚æ•°+å…³é”®ç‚¹]
    D --> G[çƒä½“è½¨è¿¹<br/>åŸå§‹+å»å™ª]
    E --> H[å§¿æ€æ•°æ®<br/>å…³é”®ç‚¹+éª¨æ¶]
    F --> I[Step 2.5: å‡»çƒäº‹ä»¶æ£€æµ‹<br/>å³°å€¼+è§’åº¦+å§¿æ€]
    G --> I
    H --> I
    I --> J[Step 2.6: å‡»çƒç±»å‹åˆ†ç±»<br/>BST Transformer]
    J --> K[Step 3: ç»¼åˆå¯è§†åŒ–<br/>è½¨è¿¹+å§¿æ€+åœºåœ°+äº‹ä»¶]
    K --> L[Step 4: æ•°æ®å¯¼å‡º<br/>CSV+JSON+è§†é¢‘]
    L --> M[è¾“å‡ºç»“æœ<br/>åˆ†ææŠ¥å‘Š+å¯è§†åŒ–]
```

### TrackNetV3 + CBAM ç½‘ç»œæ¶æ„

```mermaid
graph LR
    A[è¾“å…¥<br/>9å¸§Ã—3é€šé“] --> B[Conv2d 9â†’64]
    B --> C[Conv2d 64â†’64]
    C --> D[CBAM 64]
    D --> E[MaxPool 2Ã—2]
    E --> F[Conv2d 64â†’128]
    F --> G[Conv2d 128â†’128]
    G --> H[CBAM 128]
    H --> I[MaxPool 2Ã—2]
    I --> J[Conv2d 128â†’256]
    J --> K[Conv2d 256â†’256]
    K --> L[CBAM 256]
    L --> M[MaxPool 2Ã—2]
    M --> N[Conv2d 256â†’512]
    N --> O[Conv2d 512â†’512]
    O --> P[CBAM 512]
    P --> Q[Upsample Ã—2]
    Q --> R[Concat 768]
    R --> S[Conv2d 768â†’256]
    S --> T[Conv2d 256â†’256]
    T --> U[CBAM 256]
    U --> V[Upsample Ã—2]
    V --> W[Concat 384]
    W --> X[Conv2d 384â†’128]
    X --> Y[Conv2d 128â†’128]
    Y --> Z[CBAM 128]
    Z --> AA[Upsample Ã—2]
    AA --> AB[Concat 192]
    AB --> AC[Conv2d 192â†’64]
    AC --> AD[Conv2d 64â†’64]
    AD --> AE[CBAM 64]
    AE --> AF[Conv2d 64â†’3]
    AF --> AG[è¾“å‡º<br/>3é€šé“çƒ­åŠ›å›¾]
```

### CBAM æ³¨æ„åŠ›æœºåˆ¶è¯¦è§£

```mermaid
graph TB
    A[è¾“å…¥ç‰¹å¾å›¾] --> B[é€šé“æ³¨æ„åŠ›]
    B --> B1[å…¨å±€å¹³å‡æ± åŒ–]
    B --> B2[å…¨å±€æœ€å¤§æ± åŒ–]
    B1 --> B3[å…±äº«MLP]
    B2 --> B3
    B3 --> B4[Sigmoidæ¿€æ´»]
    B4 --> B5[é€šé“æƒé‡]
    B5 --> C[é€é€šé“ç›¸ä¹˜]
    C --> D[ç©ºé—´æ³¨æ„åŠ›]
    D --> D1[é€šé“å¹³å‡æ± åŒ–]
    D --> D2[é€šé“æœ€å¤§æ± åŒ–]
    D1 --> D3[æ‹¼æ¥]
    D2 --> D3
    D3 --> D4[å·ç§¯å±‚]
    D4 --> D5[Sigmoidæ¿€æ´»]
    D5 --> E[ç©ºé—´æƒé‡]
    E --> F[é€åƒç´ ç›¸ä¹˜]
    F --> G[è¾“å‡ºç‰¹å¾å›¾]
```

### BST Transformer æ¶æ„

```mermaid
graph TB
    A[è¾“å…¥<br/>å§¿æ€+è½¨è¿¹+ä½ç½®] --> B[TCN å§¿æ€ç¼–ç ]
    A --> C[TCN è½¨è¿¹ç¼–ç ]
    B --> D[æ—¶åºTransformer]
    C --> D
    D --> E[åˆ†ç±»Token]
    D --> F[å§¿æ€Token]
    D --> G[è½¨è¿¹Token]
    E --> H[äº¤å‰æ³¨æ„åŠ›]
    F --> H
    G --> H
    H --> I[äº¤äº’Transformer]
    I --> J[MLP Head]
    J --> K[è¾“å‡º<br/>35ç±»å‡»çƒç±»å‹]
```

### å¤„ç†æµæ°´çº¿æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant V as è¾“å…¥è§†é¢‘
    participant C as åœºåœ°æ£€æµ‹
    participant B as çƒä½“æ£€æµ‹
    participant P as å§¿æ€æ£€æµ‹
    participant E as äº‹ä»¶æ£€æµ‹
    participant S as å‡»çƒåˆ†ç±»
    participant Viz as å¯è§†åŒ–
    participant Exp as å¯¼å‡º
    
    V->>C: æ¯å¸§/é—´éš”æ£€æµ‹
    C->>C: è®¡ç®—åœºåœ°å‚æ•°
    V->>B: é€å¸§æ£€æµ‹
    B->>B: å¡å°”æ›¼æ»¤æ³¢å¹³æ»‘
    V->>P: é€å¸§æ£€æµ‹
    P->>P: çƒå‘˜åˆ†é…
    B->>E: è½¨è¿¹æ•°æ®
    P->>E: å§¿æ€æ•°æ®
    E->>E: å³°å€¼æ£€æµ‹
    E->>E: è§’åº¦åˆ†æ
    E->>E: å§¿æ€éªŒè¯
    E->>S: å‡»çƒå¸§
    P->>S: å§¿æ€æ•°æ®
    S->>S: æ—¶åºåˆ†å‰²
    S->>S: Transformeråˆ†ç±»
    C->>Viz: åœºåœ°å…³é”®ç‚¹
    B->>Viz: çƒä½“è½¨è¿¹
    P->>Viz: å§¿æ€éª¨æ¶
    E->>Viz: å‡»çƒäº‹ä»¶
    S->>Viz: å‡»çƒç±»å‹
    Viz->>Exp: ç»¼åˆè§†é¢‘
    Viz->>Exp: CSVæ•°æ®
    Viz->>Exp: JSONäº‹ä»¶
```

### GUI ç•Œé¢å¸ƒå±€

```mermaid
graph TB
    A[ä¸»çª—å£] --> B[è§†é¢‘æ’­æ”¾å™¨åŒºåŸŸ]
    A --> C[æ•°æ®å¯è§†åŒ–åŒºåŸŸ]
    A --> D[æ§åˆ¶é¢æ¿åŒºåŸŸ]
    B --> B1[è¾“å…¥è§†é¢‘æ’­æ”¾å™¨]
    B --> B2[æ£€æµ‹é¢„è§ˆæ’­æ”¾å™¨]
    B --> B3[è¾“å‡ºè§†é¢‘æ’­æ”¾å™¨]
    B --> B4[å¯¹æ¯”æ’­æ”¾å™¨]
    C --> C1[æ¦‚è§ˆæ ‡ç­¾é¡µ]
    C --> C2[å‡»çƒäº‹ä»¶æ ‡ç­¾é¡µ]
    C --> C3[CSVæ•°æ®æ ‡ç­¾é¡µ]
    C --> C4[çƒé€Ÿæ›²çº¿æ ‡ç­¾é¡µ]
    C --> C5[çƒé«˜åº¦æ ‡ç­¾é¡µ]
    C --> C6[åˆ†å¸ƒæ ‡ç­¾é¡µ]
    C --> C7[é€‰æ‰‹æ ‡ç­¾é¡µ]
    D --> D1[å‚æ•°æ ‡ç­¾é¡µ]
    D --> D2[æ—¥å¿—æ ‡ç­¾é¡µ]
    D --> D3[è¿è¡ŒçŠ¶æ€]
    D --> D4[ç»“æœæµè§ˆ]
```

### å®æ—¶å¤„ç†æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant V as è§†é¢‘æµ
    participant B as ç¼“å†²åŒº
    participant D as æ£€æµ‹å™¨
    participant P as å¤„ç†å™¨
    participant O as è¾“å‡º
    
    V->>B: è¯»å–å¸§
    B->>B: å¡«å……ç¼“å†²åŒº
    B->>D: å‘é€å¸§æ‰¹æ¬¡
    D->>D: æ£€æµ‹çƒä½“
    D->>D: æ£€æµ‹å§¿æ€
    D->>P: å‘é€æ£€æµ‹ç»“æœ
    P->>P: å¤„ç†äº‹ä»¶
    P->>P: åˆ†ç±»å‡»çƒ
    P->>O: å‘é€å¤„ç†ç»“æœ
    O->>O: å¯è§†åŒ–åˆæˆ
    O->>O: è¾“å‡ºè§†é¢‘å¸§
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

#### ç¡¬ä»¶è¦æ±‚
- **CPU**: Intel Core i5 æˆ–æ›´é«˜ï¼ˆæ¨è i7ï¼‰
- **GPU**: NVIDIA GTX 1060 æˆ–æ›´é«˜ï¼ˆæ¨è RTX 3060+ï¼‰
- **å†…å­˜**: 8GB æœ€ä½ï¼ˆæ¨è 16GBï¼‰
- **å­˜å‚¨**: 20GB å¯ç”¨ç©ºé—´
- **æ“ä½œç³»ç»Ÿ**: Windows 10/11, Ubuntu 18.04+, macOS 10.15+

#### è½¯ä»¶è¦æ±‚
- **Python**: 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- **CUDA**: 11.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
- **é©±åŠ¨**: NVIDIA é©±åŠ¨ 450.80 æˆ–æ›´é«˜

### å®‰è£…æ­¥éª¤

#### æ–¹æ³• 1: ä½¿ç”¨ pip å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/TrackNetV3_Attention.git
cd TrackNetV3_Attention

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ–
venv\Scripts\activate  # Windows

# å‡çº§ pip
pip install --upgrade pip

# å®‰è£… PyTorchï¼ˆæ ¹æ® CUDA ç‰ˆæœ¬é€‰æ‹©ï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# å®‰è£… MMPose å’Œ MMDetection
pip install openmim
mim install mmpose
mim install mmdet

# å®‰è£…å…¶ä»–ä¾èµ–
pip install opencv-python-headless
pip install pyside6
pip install pandas
pip install numpy
pip install scipy
pip install matplotlib
pip install seaborn
pip install tqdm
pip install pillow
```

#### æ–¹æ³• 2: ä½¿ç”¨ conda å®‰è£…

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n tracknet python=3.9
conda activate tracknet

# å®‰è£… PyTorch
conda install pytorch torchvision cudatoolkit=11.3 -c pytorch

# å®‰è£…å…¶ä»–ä¾èµ–
conda install opencv
conda install pandas
conda install numpy
conda install scipy
conda install matplotlib
conda install seaborn

# å®‰è£… MMPose å’Œ MMDetection
pip install openmim
mim install mmpose
mim install mmdet

# å®‰è£… PySide6
pip install pyside6
```

#### æ–¹æ³• 3: ä»æºç å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/yourusername/TrackNetV3_Attention.git
cd TrackNetV3_Attention

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### æ¨¡å‹ä¸‹è½½

#### è‡ªåŠ¨ä¸‹è½½

```bash
# è¿è¡Œä¸‹è½½è„šæœ¬
python scripts/download_models.py

# è„šæœ¬ä¼šè‡ªåŠ¨ä¸‹è½½ä»¥ä¸‹æ¨¡å‹ï¼š
# - TrackNetV3 æƒé‡: models/ball_track_attention.pt
# - åœºåœ°æ£€æµ‹æƒé‡: models/court_kpRCNN.pth
# - çƒç½‘æ£€æµ‹æƒé‡: models/net_kpRCNN.pth
# - BST æ¨¡å‹: models/bst/shuttleset_35classes/*.pt
```

#### æ‰‹åŠ¨ä¸‹è½½

```bash
# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p models/bst/shuttleset_35classes

# ä¸‹è½½æ¨¡å‹ï¼ˆç¤ºä¾‹é“¾æ¥ï¼‰
wget https://example.com/models/ball_track_attention.pt -P models/
wget https://example.com/models/court_kpRCNN.pth -P models/
wget https://example.com/models/net_kpRCNN.pth -P models/
wget https://example.com/models/bst_shuttleset.pt -P models/bst/shuttleset_35classes/
```

### å‘½ä»¤è¡Œä½¿ç”¨

#### åŸºæœ¬ç”¨æ³•

```bash
# è¿è¡Œå®Œæ•´æµæ°´çº¿
python run_combined.py \
  --video videos/test.mp4 \
  --result_dir ./results \
  --model models/ball_track_attention.pt \
  --num_frames 3 \
  --threshold 0.5 \
  --traj_len 10 \
  --device cuda \
  --pose_model rtmpose-m \
  --use_court_detection \
  --court_model models/court_kpRCNN.pth \
  --court_detection_interval 30
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | å½±å“ |
|------|------|--------|------|------|
| `--video` | è¾“å…¥è§†é¢‘è·¯å¾„ | å¿…å¡« | - | è¾“å…¥æ–‡ä»¶ |
| `--result_dir` | è¾“å‡ºç›®å½• | ./results | - | ç»“æœå­˜å‚¨ä½ç½® |
| `--model` | TrackNet æ¨¡å‹è·¯å¾„ | models/ball_track_attention.pt | - | æ£€æµ‹ç²¾åº¦ |
| `--num_frames` | è¾“å…¥å¸§æ•° | 3 | 1-9 | æ£€æµ‹ç²¾åº¦ vs é€Ÿåº¦ |
| `--threshold` | æ£€æµ‹é˜ˆå€¼ | 0.5 | 0.0-1.0 | å¬å›ç‡ vs ç²¾ç¡®ç‡ |
| `--traj_len` | è½¨è¿¹æ˜¾ç¤ºé•¿åº¦ | 10 | 1-60 | å¯è§†åŒ–æ•ˆæœ |
| `--device` | è®¾å¤‡ç±»å‹ | cuda | cuda/cpu | å¤„ç†é€Ÿåº¦ |
| `--pose_model` | å§¿æ€æ¨¡å‹ | rtmpose-m | t/s/m/l | é€Ÿåº¦ vs ç²¾åº¦ |
| `--use_court_detection` | å¯ç”¨åœºåœ°æ£€æµ‹ | True | - | çƒå‘˜åˆ†é…ç²¾åº¦ |
| `--court_model` | åœºåœ°æ£€æµ‹æ¨¡å‹ | models/court_kpRCNN.pth | - | åœºåœ°æ£€æµ‹ç²¾åº¦ |
| `--court_detection_interval` | åœºåœ°æ£€æµ‹é—´éš” | 30 | 1-300 | å¤„ç†é€Ÿåº¦ vs ç²¾åº¦ |

#### é«˜çº§ç”¨æ³•

```bash
# ä½¿ç”¨ä¸åŒçš„å§¿æ€æ¨¡å‹
python run_combined.py \
  --video videos/test.mp4 \
  --pose_model rtmpose-l  # ä½¿ç”¨å¤§æ¨¡å‹ï¼Œæ›´é«˜ç²¾åº¦

# è°ƒæ•´æ£€æµ‹å‚æ•°
python run_combined.py \
  --video videos/test.mp4 \
  --threshold 0.3 \  # é™ä½é˜ˆå€¼ï¼Œæé«˜å¬å›ç‡
  --num_frames 5 \  # å¢åŠ è¾“å…¥å¸§æ•°ï¼Œæé«˜ç²¾åº¦
  --court_detection_interval 15  # æ›´é¢‘ç¹çš„åœºåœ°æ£€æµ‹

# ä½¿ç”¨ CPU æ¨¡å¼
python run_combined.py \
  --video videos/test.mp4 \
  --device cpu  # é€‚ç”¨äºæ—  GPU ç¯å¢ƒ
```

### GUI ä½¿ç”¨

#### å¯åŠ¨ GUI

```bash
# å¯åŠ¨å›¾å½¢ç•Œé¢
python ui_pyside6/main.py
```

#### GUI ä½¿ç”¨æµç¨‹

1. **å¯¼å…¥è§†é¢‘**
   - ç‚¹å‡»"å¯¼å…¥è§†é¢‘"æŒ‰é’®
   - é€‰æ‹©è§†é¢‘æ–‡ä»¶
   - è§†é¢‘ä¼šè‡ªåŠ¨åŠ è½½åˆ°è¾“å…¥æ’­æ”¾å™¨

2. **é…ç½®å‚æ•°**
   - åœ¨"å‚æ•°"æ ‡ç­¾é¡µè°ƒæ•´å‚æ•°
   - é€‰æ‹©è®¾å¤‡ï¼ˆcuda/cpuï¼‰
   - é€‰æ‹©å§¿æ€æ¨¡å‹ï¼ˆrtmpose-t/s/m/lï¼‰
   - è®¾ç½®æ£€æµ‹é˜ˆå€¼å’Œè½¨è¿¹é•¿åº¦
   - é…ç½®åœºåœ°æ£€æµ‹å‚æ•°

3. **è¿è¡Œåˆ†æ**
   - ç‚¹å‡»"å¼€å§‹è®­ç»ƒåˆ†æ"æŒ‰é’®
   - ç³»ç»Ÿä¼šè‡ªåŠ¨æ‰§è¡Œå®Œæ•´æµæ°´çº¿
   - å¯ä»¥åœ¨"æ—¥å¿—"æ ‡ç­¾é¡µæŸ¥çœ‹å®æ—¶æ—¥å¿—
   - å¯ä»¥åœ¨"è¿è¡ŒçŠ¶æ€"æŸ¥çœ‹è¿›åº¦

4. **æŸ¥çœ‹ç»“æœ**
   - åˆ†æå®Œæˆåï¼Œç»“æœä¼šè‡ªåŠ¨åŠ è½½
   - åœ¨å„ä¸ªæ ‡ç­¾é¡µæŸ¥çœ‹ä¸åŒçš„å¯è§†åŒ–
   - åœ¨"ç»“æœæµè§ˆ"é€‰æ‹©å†å²ç»“æœ

5. **å¯¼å‡ºæ•°æ®**
   - ç‚¹å‡»"å¯¼å‡º"èœå•
   - é€‰æ‹©è¦å¯¼å‡ºçš„å†…å®¹
   - é€‰æ‹©ä¿å­˜è·¯å¾„
   - ç¡®è®¤å¯¼å‡º

#### GUI å¿«æ·é”®

| å¿«æ·é”® | åŠŸèƒ½ |
|--------|------|
| `Ctrl+O` | å¯¼å…¥è§†é¢‘ |
| `Ctrl+S` | ä¿å­˜å½“å‰é…ç½® |
| `Ctrl+R` | è¿è¡Œåˆ†æ |
| `Ctrl+T` | åœæ­¢åˆ†æ |
| `Space` | æ’­æ”¾/æš‚åœ |
| `â†/â†’` | å¿«é€€/å¿«è¿› |
| `â†‘/â†“` | ä¸Šä¸€å¸§/ä¸‹ä¸€å¸§ |
| `Ctrl+E` | å¯¼å‡ºæ•°æ® |
| `Ctrl+Q` | é€€å‡ºç¨‹åº |

---

## ï¿½ ç®—æ³•è¯¦è§£

### TrackNetV3 + CBAM å®Œæ•´å®ç°

#### Conv å—å®ç°
```python
class Conv(nn.Module):
    def __init__(self, ic, oc, k=(3, 3), p="same", act=True):
        super().__init__()
        self.conv = nn.Conv2d(ic, oc, kernel_size=k, padding=p)
        self.bn = nn.BatchNorm2d(oc)
        self.act = nn.ReLU() if act else nn.Identity()

    def forward(self, x):
        return self.bn(self.act(self.conv(x)))
```

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- **å·ç§¯å±‚**: 3Ã—3 å·ç§¯æ ¸ï¼Œsame padding ä¿æŒå°ºå¯¸
- **æ‰¹å½’ä¸€åŒ–**: åŠ é€Ÿè®­ç»ƒï¼Œæé«˜ç¨³å®šæ€§
- **ReLU æ¿€æ´»**: éçº¿æ€§æ¿€æ´»å‡½æ•°

#### é€šé“æ³¨æ„åŠ›ï¼ˆChannel Attentionï¼‰

##### CBAM é€šé“æ³¨æ„åŠ›æµç¨‹å›¾

```mermaid
graph TB
    A[è¾“å…¥ç‰¹å¾å›¾<br/>HÃ—WÃ—C] --> B[å…¨å±€å¹³å‡æ± åŒ–]
    A --> C[å…¨å±€æœ€å¤§æ± åŒ–]
    
    B --> D[å…±äº« MLP]
    C --> D
    
    D --> E[é™ç»´: C â†’ C/r]
    E --> F[ReLU æ¿€æ´»]
    F --> G[å‡ç»´: C/r â†’ C]
    
    G --> H[å¹³å‡æ± åŒ–è¾“å‡º]
    G --> I[æœ€å¤§æ± åŒ–è¾“å‡º]
    
    H --> J[å…ƒç´ ç›¸åŠ ]
    I --> J
    
    J --> K[Sigmoid æ¿€æ´»]
    K --> L[é€šé“æƒé‡<br/>1Ã—1Ã—C]
    
    L --> M[å¯å­¦ä¹ ç¼©æ”¾]
    M --> N[ç¼©æ”¾åçš„æƒé‡]
    
    N --> O[é€é€šé“ç›¸ä¹˜]
    O --> P[è¾“å‡ºç‰¹å¾å›¾<br/>HÃ—WÃ—C]
```

```python
class ChannelAttention(nn.Module):
    def __init__(self, in_channels, reduction_ratio=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
        
        self.scale = nn.Parameter(torch.zeros(1))  # å¯å­¦ä¹ ç¼©æ”¾å‚æ•°
        
        self._init_weights()

    def _init_weights(self):
        for m in self.fc.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.zeros_(m.weight)

    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        out = avg_out + max_out
        att = self.sigmoid(out)
        return 1.0 + self.scale * (att - 1.0)
```

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- **å…¨å±€å¹³å‡æ± åŒ–**: æ•æ‰å…¨å±€ç‰¹å¾
- **å…¨å±€æœ€å¤§æ± åŒ–**: æ•æ‰æ˜¾è‘—ç‰¹å¾
- **å…±äº« MLP**: é™ä½ç»´åº¦åæ¢å¤ï¼Œå‡å°‘å‚æ•°
- **å¯å­¦ä¹ ç¼©æ”¾**: è‡ªé€‚åº”è°ƒæ•´æ³¨æ„åŠ›å¼ºåº¦

#### ç©ºé—´æ³¨æ„åŠ›ï¼ˆSpatial Attentionï¼‰

##### CBAM ç©ºé—´æ³¨æ„åŠ›æµç¨‹å›¾

```mermaid
graph TB
    A[è¾“å…¥ç‰¹å¾å›¾<br/>HÃ—WÃ—C] --> B[é€šé“å¹³å‡æ± åŒ–]
    A --> C[é€šé“æœ€å¤§æ± åŒ–]
    
    B --> D[æ²¿é€šé“ç»´åº¦å¹³å‡<br/>HÃ—WÃ—1]
    C --> E[æ²¿é€šé“ç»´åº¦æœ€å¤§<br/>HÃ—WÃ—1]
    
    D --> F[æ‹¼æ¥<br/>HÃ—WÃ—2]
    E --> F
    
    F --> G[7Ã—7 å·ç§¯]
    G --> H[ç©ºé—´ç‰¹å¾<br/>HÃ—WÃ—1]
    
    H --> I[Sigmoid æ¿€æ´»]
    I --> J[ç©ºé—´æƒé‡<br/>HÃ—WÃ—1]
    
    J --> K[å¯å­¦ä¹ ç¼©æ”¾]
    K --> L[ç¼©æ”¾åçš„æƒé‡]
    
    L --> M[é€åƒç´ ç›¸ä¹˜]
    M --> N[è¾“å‡ºç‰¹å¾å›¾<br/>HÃ—WÃ—C]
```

```python
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super().__init__()
        padding = kernel_size // 2
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()
        
        self.scale = nn.Parameter(torch.zeros(1))  # å¯å­¦ä¹ ç¼©æ”¾å‚æ•°
        
        self._init_weights()

    def _init_weights(self):
        nn.init.zeros_(self.conv.weight)

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x_cat = torch.cat([avg_out, max_out], dim=1)
        out = self.conv(x_cat)
        att = self.sigmoid(out)
        return 1.0 + self.scale * (att - 1.0)
```

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- **é€šé“å¹³å‡æ± åŒ–**: æ²¿é€šé“ç»´åº¦å¹³å‡
- **é€šé“æœ€å¤§æ± åŒ–**: æ²¿é€šé“ç»´åº¦æœ€å¤§
- **7Ã—7 å·ç§¯**: æ•æ‰ç©ºé—´å…³ç³»
- **å¯å­¦ä¹ ç¼©æ”¾**: è‡ªé€‚åº”è°ƒæ•´æ³¨æ„åŠ›å¼ºåº¦

### å¡å°”æ›¼æ»¤æ³¢å™¨å®Œæ•´å®ç°

#### å¡å°”æ›¼æ»¤æ³¢å™¨å·¥ä½œæµç¨‹å›¾

```mermaid
graph TB
    A[åˆå§‹åŒ–] --> B[è®¾ç½®çŠ¶æ€å‘é‡ x]
    A --> C[è®¾ç½®åæ–¹å·® P]
    A --> D[è®¾ç½®çŠ¶æ€è½¬ç§»çŸ©é˜µ F]
    A --> E[è®¾ç½®è§‚æµ‹çŸ©é˜µ H]
    A --> F[è®¾ç½®è¿‡ç¨‹å™ªå£° Q]
    A --> G[è®¾ç½®æµ‹é‡å™ªå£° R]
    
    B --> H[é¢„æµ‹æ­¥éª¤]
    C --> H
    D --> H
    H --> I[çŠ¶æ€é¢„æµ‹ xÌ‚ = F @ x]
    H --> J[åæ–¹å·®é¢„æµ‹ PÌ‚ = F @ P @ F.T + Q]
    
    K[è§‚æµ‹æ•°æ® z] --> L[æ›´æ–°æ­¥éª¤]
    I --> L
    J --> L
    L --> M[è®¡ç®—æ–°æ¯ y = z - H @ x]
    L --> N[è®¡ç®—æ–°æ¯åæ–¹å·® S = H @ P @ H.T + R]
    L --> O[è®¡ç®—å¡å°”æ›¼å¢ç›Š K = P @ H.T @ Sâ»Â¹]
    O --> P[çŠ¶æ€æ›´æ–° x = x + K @ y]
    O --> Q[åæ–¹å·®æ›´æ–° P = (I - K @ H) @ P]
    
    P --> R[è¾“å‡ºçŠ¶æ€]
    Q --> R
```

#### çŠ¶æ€ç©ºé—´æ¨¡å‹
```
çŠ¶æ€å‘é‡: x = [x, y, vx, vy]^T
è§‚æµ‹å‘é‡: z = [x, y]^T
```

#### çŠ¶æ€è½¬ç§»çŸ©é˜µ F
```python
self.F = np.array([
    [1, 0, dt, 0],   # x = x + vx*dt
    [0, 1, 0, dt],   # y = y + vy*dt
    [0, 0, 1, 0],    # vx = vx
    [0, 0, 0, 1]     # vy = vy
], dtype=np.float64)
```

#### è§‚æµ‹çŸ©é˜µ H
```python
self.H = np.array([
    [1, 0, 0, 0],   # è§‚æµ‹ x
    [0, 1, 0, 0]    # è§‚æµ‹ y
], dtype=np.float64)
```

#### è¿‡ç¨‹å™ªå£° Q å’Œæµ‹é‡å™ªå£° R
```python
self.Q = np.eye(4) * process_noise      # è¿‡ç¨‹å™ªå£°åæ–¹å·®
self.R = np.eye(2) * measurement_noise  # æµ‹é‡å™ªå£°åæ–¹å·®
```

#### é¢„æµ‹æ­¥éª¤
```python
def predict(self):
    if not self.initialized:
        return None
        
    self.x = self.F @ self.x  # çŠ¶æ€é¢„æµ‹
    self.P = self.F @ self.P @ self.F.T + self.Q  # åæ–¹å·®é¢„æµ‹
    return self.x[:2]
```

#### æ›´æ–°æ­¥éª¤
```python
def update(self, measurement):
    if not self.initialized:
        self.init(measurement[0], measurement[1])
        return measurement
    
    z = np.array(measurement, dtype=np.float64)
    y = z - self.H @ self.x  # æ–°æ¯ï¼ˆinnovationï¼‰
    S = self.H @ self.P @ self.H.T + self.R  # æ–°æ¯åæ–¹å·®
    K = self.P @ self.H.T @ np.linalg.inv(S)  # å¡å°”æ›¼å¢ç›Š
    
    self.x = self.x + K @ y  # çŠ¶æ€æ›´æ–°
    self.P = (np.eye(4) - K @ self.H) @ self.P  # åæ–¹å·®æ›´æ–°
    return self.x[:2]
```

#### è½¨è¿¹å¹³æ»‘å™¨
```python
class KalmanTrajectorySmoother:
    def __init__(self, max_gap=10, process_noise=1.0, measurement_noise=10.0):
        self.max_gap = max_gap  # æœ€å¤§é—´éš™å¸§æ•°
        self.process_noise = process_noise
        self.measurement_noise = measurement_noise
```

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- **é—´éš™å¤„ç†**: æ™ºèƒ½å¤„ç†æ£€æµ‹é—´éš™
- **è·ç¦»éªŒè¯**: é˜²æ­¢å¼‚å¸¸è·³è·ƒ
- **è‡ªé€‚åº”å‚æ•°**: å¯è°ƒèŠ‚å™ªå£°å‚æ•°

### BST Transformer å®Œæ•´å®ç°

#### BST æ¶æ„æµç¨‹å›¾

```mermaid
graph TB
    A[è¾“å…¥æ•°æ®] --> B[å§¿æ€æ•°æ®]
    A --> C[è½¨è¿¹æ•°æ®]
    A --> D[ä½ç½®æ•°æ®]
    
    B --> E[TCN å§¿æ€ç¼–ç ]
    C --> F[TCN è½¨è¿¹ç¼–ç ]
    D --> G[ä½ç½®ç¼–ç ]
    
    E --> H[æ—¶åº Transformer]
    F --> H
    G --> H
    
    H --> I[åˆ†ç±» Token]
    H --> J[å§¿æ€ Token]
    H --> K[è½¨è¿¹ Token]
    
    I --> L[äº¤å‰æ³¨æ„åŠ›]
    J --> L
    K --> L
    
    L --> M[äº¤äº’ Transformer]
    M --> N[MLP Head]
    N --> O[è¾“å‡º 35 ç±»å‡»çƒç±»å‹]
```

#### å¤šå¤´äº¤å‰æ³¨æ„åŠ›
```python
class MultiHeadCrossAttention(nn.Module):
    def __init__(self, d_model, d_head, n_head, drop_p):
        super().__init__()
        d_cat = d_head * n_head
        
        self.h = n_head
        self.to_q = nn.Linear(d_model, d_cat, bias=False)
        self.to_kv = nn.Linear(d_model, d_cat * 2, bias=False)
        self.scale = d_head**-0.5  # ç¼©æ”¾å› å­
        
        self.attend = nn.Sequential(
            nn.Softmax(dim=-1),
            nn.Dropout(drop_p)
        )
        
        self.tail = nn.Sequential(
            nn.Linear(d_cat, d_model),
            nn.Dropout(drop_p, inplace=True)
        ) if n_head != 1 or d_cat != d_model else nn.Identity()
```

#### äº¤å‰æ³¨æ„åŠ›æœºåˆ¶
```python
def forward(self, x1: Tensor, x2: Tensor, mask: Tensor = None):
    q: Tensor = self.to_q(x1)
    kv: Tensor = self.to_kv(x2)
    b, t, _ = q.shape
    
    q = q.view(b, t, self.h, -1).transpose(1, 2)
    kv = kv.view(b, t, self.h, -1).chunk(2, dim=-1)
    k, v = map(lambda ts: ts.transpose(1, 2), kv)
    
    # ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
    dots: Tensor = (q.contiguous() @ k.transpose(-1, -2).contiguous()) * self.scale
    
    # æ©ç å¤„ç†
    if mask is not None:
        mask = mask.view(b, 1, 1, t)
        dots = dots.masked_fill(mask == 0.0, -torch.inf)
    
    # æ³¨æ„åŠ›æƒé‡
    coef = self.attend(dots)
    attension: Tensor = coef @ v.contiguous()
    
    # è¾“å‡ºæŠ•å½±
    out = attension.transpose(1, 2).reshape(b, t, -1)
    out = self.tail(out)
    return out
```

#### TCN æ—¶åºç¼–ç 
```python
class TCN(nn.Module):
    def __init__(self, in_dim, channels, kernel_size, drop_p):
        super().__init__()
        self.conv1 = nn.Conv1d(in_dim, channels[0], kernel_size,
                               padding=kernel_size//2)
        self.conv2 = nn.Conv1d(channels[0], channels[1], kernel_size,
                               padding=kernel_size//2)
        self.dropout = nn.Dropout(drop_p)
```

#### BST æ¨¡å‹å˜ä½“
- **BST**: åŸºç¡€ç‰ˆæœ¬
- **BST_CG**: æ·»åŠ  Clean Gate
- **BST_AP**: æ·»åŠ  Aim Playerï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
- **BST_CG_AP**: å®Œæ•´ç‰ˆæœ¬ï¼ˆClean Gate + Aim Playerï¼‰

---

## âš¡ å‡»çƒäº‹ä»¶æ£€æµ‹è¯¦è§£

### æ£€æµ‹æµç¨‹

```mermaid
graph TB
    A[è½¨è¿¹æ•°æ®] --> B[å³°å€¼æ£€æµ‹]
    A --> C[è°·å€¼æ£€æµ‹]
    B --> D[è§’åº¦è®¡ç®—]
    C --> D
    D --> E[è§’åº¦é˜ˆå€¼è¿‡æ»¤]
    E --> F[è¿ç»­æ€§éªŒè¯]
    F --> G[å§¿æ€éªŒè¯]
    G --> H[è½åœ°å¸§è¿‡æ»¤]
    H --> I[æœ€ç»ˆå‡»çƒå¸§]
```

### è¯¦ç»†æ£€æµ‹æµç¨‹å›¾

```mermaid
graph TB
    A[è¾“å…¥è½¨è¿¹æ•°æ®] --> B{æ•°æ®é¢„å¤„ç†}
    B --> B1[æå–æœ‰æ•ˆç‚¹]
    B --> B2[è®¡ç®— Y åæ ‡]
    
    B1 --> C{å³°å€¼æ£€æµ‹}
    B2 --> C
    C --> C1[find_peaks]
    C --> C2[find_peaks è´Ÿå€¼]
    
    C1 --> D{è§’åº¦è®¡ç®—}
    C2 --> D
    D --> D1[è®¡ç®—æ–œç‡]
    D --> D2[è®¡ç®—å‘é‡]
    D --> D3[è®¡ç®—è§’åº¦]
    
    D1 --> E{è§’åº¦è¿‡æ»¤}
    D2 --> E
    D3 --> E
    E --> E1[è§’åº¦ > é˜ˆå€¼?]
    E1 -->|æ˜¯| F[ä¿ç•™å‡»çƒç‚¹]
    E1 -->|å¦| G[ä¸¢å¼ƒå‡»çƒç‚¹]
    
    F --> H{è¿ç»­æ€§éªŒè¯}
    G --> H
    H --> H1[æ£€æŸ¥åç»­å¸§]
    H --> H2[è®¡ç®—ç§»åŠ¨è·ç¦»]
    H --> H3[ç§»åŠ¨ >= é˜ˆå€¼?]
    
    H1 --> I{å§¿æ€éªŒè¯}
    H2 --> I
    H3 --> I
    I --> I1[è®¡ç®—çƒå‘˜è´¨å¿ƒ]
    I --> I2[è®¡ç®—çƒ-çƒå‘˜è·ç¦»]
    I --> I3[é€‰æ‹©æœ€è¿‘çƒå‘˜]
    
    I1 --> J{è½åœ°å¸§æ£€æµ‹}
    I2 --> J
    I3 --> J
    J --> J1[è®¡ç®—åœ°é¢ Y åæ ‡]
    J --> J2[è¯†åˆ«è½åœ°å¸§]
    
    J1 --> K[æœ€ç»ˆè¾“å‡º]
    J2 --> K
    J3 --> K
    K --> K1[å‡»çƒå¸§åˆ—è¡¨]
    K --> K2[å‡»çƒçƒå‘˜åˆ—è¡¨]
```

### å³°å€¼å’Œè°·å€¼æ£€æµ‹
```python
from scipy.signal import find_peaks

peaks, properties = find_peaks(y, prominence=prominence)
valleys, _ = find_peaks(-y, prominence=prominence)
```

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- **prominence**: å³°å€¼æ˜¾è‘—æ€§å‚æ•°ï¼ˆé»˜è®¤ 2.0ï¼‰
- **peaks**: å³°å€¼ç´¢å¼•ï¼ˆå¯èƒ½å¯¹åº”å‡»çƒç‚¹ï¼‰
- **valleys**: è°·å€¼ç´¢å¼•ï¼ˆå¯èƒ½å¯¹åº”å‡»çƒç‚¹ï¼‰

### è§’åº¦è®¡ç®—
```python
def _calculate_angle(self, line1, line2):
    x1, y1, x2, y2 = line1
    x3, y3, x4, y4 = line2
    
    vec1 = np.array([x2 - x1, y2 - y1])
    vec2 = np.array([x4 - x3, y4 - y3])
    
    unit_vec1 = vec1 / (np.linalg.norm(vec1) + 1e-8)
    unit_vec2 = vec2 / (np.linalg.norm(vec2) + 1e-8)
    
    dot_product = np.dot(unit_vec1, unit_vec2)
    dot_product = np.clip(dot_product, -1.0, 1.0)
    
    angle = np.degrees(np.arccos(dot_product))
    return angle
```

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- **å‘é‡å½’ä¸€åŒ–**: å°†å‘é‡è½¬æ¢ä¸ºå•ä½å‘é‡
- **ç‚¹ç§¯è®¡ç®—**: è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯
- **è§’åº¦è½¬æ¢**: ä½¿ç”¨ arccos è®¡ç®—è§’åº¦å¹¶è½¬æ¢ä¸ºåº¦æ•°

### å§¿æ€éªŒè¯
```python
def _filter_hits_by_pose(self, hit_frames):
    hit_players = []
    
    for frame_idx in hit_frames:
        ball_pos = np.array(trajectory_data[frame_idx][:2])
        
        # è®¡ç®—æ¯ä¸ªçƒå‘˜åˆ°çƒçš„è·ç¦»
        dist_reached = 1e99
        reached_by = 0
        
        for player_idx in range(2):
            pose_data = poses[frame_idx, player_idx]
            pose_centroid = self._get_pose_centroid(pose_data)
            
            if pose_centroid is not None:
                dist = np.linalg.norm(ball_pos - pose_centroid)
                if dist < dist_reached:
                    dist_reached = dist
                    reached_by = player_idx + 1
        
        hit_players.append(reached_by)
    return hit_players
```

### è¿ç»­æ€§éªŒè¯
```python
def _validate_hit_continuation(self, hit_frames, min_continuation_frames=5, 
                             min_movement_threshold=20):
    validated_hits = []
    
    for hit_frame in hit_frames:
        movement_count = 0
        
        for i in range(1, min_continuation_frames + 1):
            if hit_frame + i >= len(trajectory_data):
                break
            
            next_data = trajectory_data[hit_frame + i]
            if next_data is None or len(next_data) < 2:
                continue
            
            distance = np.sqrt(
                (next_data[0] - hit_data[0])**2 + 
                (next_data[1] - hit_data[1])**2
            )
            
            if distance >= min_movement_threshold:
                movement_count += 1
        
        if movement_count >= 1:
            validated_hits.append(hit_frame)
    
    return validated_hits
```

### è½åœ°å¸§æ£€æµ‹
```python
def _detect_landing_frame(self):
    valid_y = [data[1] for data in trajectory_data 
                if data is not None and len(data) >= 2]
    
    ground_y = np.percentile(valid_y, 90)
    
    for i in range(len(valid_y) - 1, max(0, len(valid_y) - 50), -1):
        if valid_y[i] >= ground_y - 20:
            return i
    
    return None
```

---

## ğŸ¾ å‡»çƒç±»å‹åˆ†ç±»è¯¦è§£

### éª¨éª¼å¯¹å®šä¹‰

#### éª¨éª¼ç»“æ„æµç¨‹å›¾

```mermaid
graph TB
    A[å§¿æ€å…³é”®ç‚¹] --> B{éª¨éª¼å¯¹}
    B --> B1[å¤´éƒ¨éª¨éª¼]
    B --> B2[ä¸Šè‚¢éª¨éª¼]
    B --> B3[èº¯å¹²éª¨éª¼]
    B --> B4[ä¸‹è‚¢éª¨éª¼]
    
    B1 --> C1[(0,1)]
    B1 --> C2[(0,2)]
    B1 --> C3[(1,2)]
    B1 --> C4[(1,3)]
    B1 --> C5[(2,4)]
    
    B2 --> C6[(3,5)]
    B2 --> C7[(5,7)]
    B2 --> C8[(7,9)]
    B2 --> C9[(6,8)]
    B2 --> C10[(8,10)]
    
    B3 --> C11[(5,6)]
    B3 --> C12[(5,11)]
    B3 --> C13[(6,12)]
    B3 --> C14[(11,12)]
    
    B4 --> C15[(11,13)]
    B4 --> C16[(13,15)]
    B4 --> C17[(12,14)]
    B4 --> C18[(14,16)]
```

### éª¨éª¼è®¡ç®—
```python
def create_bones(joints: np.ndarray, pairs) -> np.ndarray:
    bones = []
    for start, end in pairs:
        start_j = joints[:, :, start, :]
        end_j = joints[:, :, end, :]
        bone = np.where((start_j != 0.0) & (end_j != 0.0), 
                      end_j - start_j, 0.0)
        bones.append(bone)
    return np.stack(bones, axis=-2)
```

### æ—¶åºåˆ†å‰²
```python
def prepare_hit_segment(self, trajectory_data, poses, hit_frame, seq_len=100):
    # ç¡®å®šç‰‡æ®µèŒƒå›´
    if hit_frame < seq_len // 2:
        start_frame = 0
        end_frame = min(seq_len, len(trajectory_data))
    else:
        start_frame = hit_frame - seq_len // 2
        end_frame = min(hit_frame + seq_len // 2, len(trajectory_data))
    
    # è®¡ç®—å¡«å……
    segment_length = end_frame - start_frame
    if segment_length < seq_len:
        pad_before = (seq_len - segment_length) // 2
        pad_after = seq_len - segment_length - pad_before
    else:
        pad_before = 0
        pad_after = 0
    
    # å‡†å¤‡æ•°æ®
    n_joints = 17
    human_pose = np.zeros((seq_len, 2, n_joints, 2))
    shuttle = np.zeros((seq_len, 2))
    pos = np.zeros((seq_len, 2, 2))
    
    # å¡«å……æ•°æ®
    for i in range(segment_length):
        frame_idx = start_frame + i
        output_idx = pad_before + i
        
        # çƒä½“è½¨è¿¹
        if frame_idx < len(trajectory_data):
            traj = trajectory_data[frame_idx]
            if traj is not None and len(traj) >= 2:
                shuttle[output_idx] = [traj[0], traj[1]]
        
        # å§¿æ€æ•°æ®
        if poses is not None and frame_idx < len(poses):
            for player_idx in range(2):
                pose_data = poses[frame_idx, player_idx]
                if pose_data is not None:
                    for joint_idx in range(n_joints):
                        x, y = pose_data[joint_idx, 0], pose_data[joint_idx, 1]
                        if x > 0 and y > 0:
                            human_pose[output_idx, player_idx, joint_idx] = [x, y]
                            pos[output_idx, player_idx] = [x, y]
    
    # è®¡ç®—éª¨éª¼
    pairs = get_bone_pairs('coco')
    bones = create_bones(human_pose, pairs)
    
    # è®¡ç®—éª¨éª¼ä¸­ç‚¹
    mid_joints = []
    for start, end in pairs:
        start_j = human_pose[:, :, start, :]
        end_j = human_pose[:, :, end, :]
        mid_j = np.where((start_j != 0.0) & (end_j != 0.0), 
                      (start_j + end_j) / 2, 0.0)
        mid_joints.append(mid_j)
    bones_center = np.stack(mid_joints, axis=-2)
    
    # æ‹¼æ¥å§¿æ€å’Œéª¨éª¼
    human_pose = np.concatenate((human_pose, bones_center), axis=-2)
    
    return human_pose, shuttle, pos
```

### 35 ç§å‡»çƒç±»å‹åˆ—è¡¨
```python
stroke_types = [
    # æ­£æ‰‹å‡»çƒ (0-17)
    0: "æ­£æ‰‹é«˜è¿œçƒ", 1: "æ­£æ‰‹åŠçƒ", 2: "æ­£æ‰‹æ€çƒ",
    3: "æ­£æ‰‹å¹³æŠ½", 4: "æ­£æ‰‹ç½‘å‰çƒ", 5: "æ­£æ‰‹æŒ‘çƒ",
    6: "æ­£æ‰‹æ¨çƒ", 7: "æ­£æ‰‹æ‰‘çƒ", 8: "æ­£æ‰‹åˆ‡çƒ",
    9: "æ­£æ‰‹æ—‹è½¬çƒ", 10: "æ­£æ‰‹çŸ­å‘çƒ", 11: "æ­£æ‰‹é•¿å‘çƒ",
    12: "æ­£æ‰‹é˜²å®ˆ", 13: "æ­£æ‰‹æ–œçº¿çƒ", 14: "æ­£æ‰‹ç›´çº¿çƒ",
    15: "æ­£æ‰‹æŒ‘é«˜çƒ", 16: "æ­£æ‰‹åŠæ€çƒ", 17: "æ­£æ‰‹é‡æ€",
    
    # åæ‰‹å‡»çƒ (18-34)
    18: "åæ‰‹é«˜è¿œçƒ", 19: "åæ‰‹åŠçƒ", 20: "åæ‰‹æ€çƒ",
    21: "åæ‰‹å¹³æŠ½", 22: "åæ‰‹ç½‘å‰çƒ", 23: "åæ‰‹æŒ‘çƒ",
    24: "åæ‰‹æ¨çƒ", 25: "åæ‰‹æ‰‘çƒ", 26: "åæ‰‹åˆ‡çƒ",
    27: "åæ‰‹æ—‹è½¬çƒ", 28: "åæ‰‹çŸ­å‘çƒ", 29: "åæ‰‹é•¿å‘çƒ",
    30: "åæ‰‹é˜²å®ˆ", 31: "åæ‰‹æ–œçº¿çƒ", 32: "åæ‰‹ç›´çº¿çƒ",
    33: "åæ‰‹æŒ‘é«˜çƒ", 34: "åæ‰‹åŠæ€çƒ", 35: "åæ‰‹é‡æ€"
]
```

### å®é™…æ•°æ®ç¤ºä¾‹
```json
{
  "frame": 36,
  "player": 2,
  "stroke_type_id": 10,
  "stroke_type_name": "æ­£æ‰‹é«˜è¿œçƒ",
  "stroke_type_name_en": "forehand_lift"
}
```

---

## ğŸ“„ å®é™…è¾“å‡ºæ•°æ®ç¤ºä¾‹

### å‡»çƒäº‹ä»¶ JSON ç¤ºä¾‹
```json
[
  {
    "frame": 36,
    "player": 2
  },
  {
    "frame": 85,
    "player": 1
  },
  {
    "frame": 111,
    "player": 2
  },
  {
    "frame": 123,
    "player": 1
  }
]
```

### å‡»çƒç±»å‹ JSON ç¤ºä¾‹
```json
[
  {
    "frame": 36,
    "player": 2,
    "stroke_type_id": 10,
    "stroke_type_name": "æ­£æ‰‹é«˜è¿œçƒ",
    "stroke_type_name_en": "forehand_lift"
  },
  {
    "frame": 85,
    "player": 1,
    "stroke_type_id": 10,
    "stroke_type_name": "æ­£æ‰‹é«˜è¿œçƒ",
    "stroke_type_name_en": "forehand_lift"
  },
  {
    "frame": 254,
    "player": 1,
    "stroke_type_id": 19,
    "stroke_type_name": "åæ‰‹æ—‹è½¬çƒ",
    "stroke_type_name_en": "backhand_spin"
  }
]
```

### æ•°æ®ç»Ÿè®¡ç¤ºä¾‹
| ç»Ÿè®¡é¡¹ | æ•°å€¼ |
|--------|------|
| æ€»å‡»çƒæ¬¡æ•° | 20 |
| çƒå‘˜ 1 å‡»çƒæ¬¡æ•° | 12 |
| çƒå‘˜ 2 å‡»çƒæ¬¡æ•° | 8 |
| æœ€å¸¸è§å‡»çƒç±»å‹ | æ­£æ‰‹é«˜è¿œçƒ (15æ¬¡) |
| å‡»çƒé—´éš”å¹³å‡å€¼ | 18.5 å¸§ |
| å‡»çƒé—´éš”æ ‡å‡†å·® | 12.3 å¸§ |

---

## ğŸ’¡ é«˜çº§ä½¿ç”¨æŠ€å·§

### æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### æ€§èƒ½ä¼˜åŒ–æµç¨‹å›¾

```mermaid
graph TB
    A[åŸå§‹ä»£ç ] --> B{ä¼˜åŒ–ç›®æ ‡}
    B --> B1[GPU ä¼˜åŒ–]
    B --> B2[CPU ä¼˜åŒ–]
    B --> B3[å†…å­˜ä¼˜åŒ–]
    
    B1 --> C1[cuDNN benchmark]
    B1 --> C2[æ··åˆç²¾åº¦è®­ç»ƒ]
    B1 --> C3[æ¢¯åº¦ç´¯ç§¯]
    B1 --> C4[éé˜»å¡å¼‚æ­¥ä¼ è¾“]
    B1 --> C5[pin_memory]
    
    B2 --> D1[å¤šè¿›ç¨‹å¤„ç†]
    B2 --> D2[numba åŠ é€Ÿ]
    
    B3 --> E1[ä½¿ç”¨ç”Ÿæˆå™¨]
    B3 --> E2[å†…å­˜æ˜ å°„]
    B3 --> E3[åŠæ—¶é‡Šæ”¾å†…å­˜]
    
    C1 --> F[ä¼˜åŒ–åä»£ç ]
    C2 --> F
    C3 --> F
    C4 --> F
    C5 --> F
    
    D1 --> F
    D2 --> F
    
    E1 --> F
    E2 --> F
    E3 --> F
    
    F --> G[æ€§èƒ½æå‡]
```

#### 1. æ‰¹å¤„ç†ä¼˜åŒ–
```python
# ä½¿ç”¨ DataLoader æ‰¹å¤„ç†
from torch.utils.data import DataLoader

dataloader = DataLoader(
    dataset,
    batch_size=4,  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
    num_workers=4,  # å¤šçº¿ç¨‹åŠ è½½
    pin_memory=True,  # é”é¡µå†…å­˜
    prefetch_factor=2  # é¢„å–å› å­
)
```

#### 2. æ··åˆç²¾åº¦è®­ç»ƒ
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = model(inputs)
    loss = criterion(outputs, targets)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

#### 3. æ¢¯åº¦ç´¯ç§¯
```python
accumulation_steps = 4
for i, batch in enumerate(dataloader):
    outputs = model(batch)
    loss = criterion(outputs, targets)
    loss = loss / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### å‚æ•°è°ƒä¼˜æŠ€å·§

#### å‚æ•°è°ƒä¼˜æµç¨‹å›¾

```mermaid
graph TB
    A[å¼€å§‹è°ƒä¼˜] --> B{é€‰æ‹©ç›®æ ‡}
    B --> B1[æé«˜å¬å›ç‡]
    B --> B2[æé«˜ç²¾ç¡®ç‡]
    B --> B3[å¹³è¡¡é…ç½®]
    
    B1 --> C1[é™ä½é˜ˆå€¼]
    B1 --> C2[é™ä½è§’åº¦é˜ˆå€¼]
    B1 --> C3[å‡å°å¸§é—´éš”]
    
    B2 --> D1[æé«˜é˜ˆå€¼]
    B2 --> D2[æé«˜è§’åº¦é˜ˆå€¼]
    B2 --> D3[å¢å¤§å¸§é—´éš”]
    
    B3 --> E1[ä½¿ç”¨é»˜è®¤å€¼]
    B3 --> E2[å¾®è°ƒå‚æ•°]
    
    C1 --> F[è¿è¡Œåˆ†æ]
    C2 --> F
    C3 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    E1 --> F
    E2 --> F
    
    F --> G[è¯„ä¼°ç»“æœ]
    G --> H{ç»“æœæ»¡æ„?}
    
    H -->|æ˜¯| I[ä¿å­˜é…ç½®]
    H -->|å¦| J[è°ƒæ•´å‚æ•°]
    J --> B
```

#### äº‹ä»¶æ£€æµ‹å‚æ•°
```python
# é«˜å¬å›ç‡é…ç½®ï¼ˆé€‚åˆè®­ç»ƒåˆ†æï¼‰
event_detector = EventDetector(trajectory_data, poses)
hit_frames, hit_players = event_detector.detect_hits(
    fps=25,
    prominence=1.0,          # é™ä½æ˜¾è‘—æ€§
    angle_threshold=10,        # é™ä½è§’åº¦é˜ˆå€¼
    min_frame_gap=5,          # å‡å°å¸§é—´éš”
    min_continuation_frames=2,  # å‡å°‘è¿ç»­å¸§è¦æ±‚
    min_movement_threshold=5    # å‡å°ç§»åŠ¨é˜ˆå€¼
)

# é«˜ç²¾ç¡®ç‡é…ç½®ï¼ˆé€‚åˆæ¯”èµ›åˆ†æï¼‰
event_detector = EventDetector(trajectory_data, poses)
hit_frames, hit_players = event_detector.detect_hits(
    fps=25,
    prominence=3.0,          # æé«˜æ˜¾è‘—æ€§
    angle_threshold=20,        # æé«˜è§’åº¦é˜ˆå€¼
    min_frame_gap=10,         # å¢å¤§å¸§é—´éš”
    min_continuation_frames=5,  # å¢åŠ è¿ç»­å¸§è¦æ±‚
    min_movement_threshold=20   # å¢å¤§ç§»åŠ¨é˜ˆå€¼
)
```

#### å¡å°”æ›¼æ»¤æ³¢å‚æ•°
```python
# å¹³æ»‘é…ç½®ï¼ˆé€‚åˆä½è´¨é‡è§†é¢‘ï¼‰
smoother = KalmanTrajectorySmoother(
    max_gap=10,
    process_noise=0.5,      # é™ä½è¿‡ç¨‹å™ªå£°
    measurement_noise=20.0    # æé«˜æµ‹é‡å™ªå£°
)

# ç´§è·Ÿé…ç½®ï¼ˆé€‚åˆé«˜è´¨é‡è§†é¢‘ï¼‰
smoother = KalmanTrajectorySmoother(
    max_gap=5,
    process_noise=2.0,       # æé«˜è¿‡ç¨‹å™ªå£°
    measurement_noise=5.0     # é™ä½æµ‹é‡å™ªå£°
)
```

### æ•…éšœæ’é™¤æŠ€å·§

#### 1. å†…å­˜ä¸è¶³
```python
# æ¸…ç† GPU ç¼“å­˜
import torch
torch.cuda.empty_cache()

# å‡å°æ‰¹æ¬¡å¤§å°
batch_size = 1

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
from torch.utils.checkpoint import checkpoint
output = checkpoint(model, input)
```

#### 2. æ£€æµ‹å¤±è´¥
```python
# æ£€æŸ¥è¾“å…¥æ•°æ®
print(f"è½¨è¿¹æ•°æ®é•¿åº¦: {len(trajectory_data)}")
print(f"æœ‰æ•ˆè½¨è¿¹ç‚¹æ•°: {sum(1 for d in trajectory_data if d is not None)}")
print(f"å§¿æ€æ•°æ®å½¢çŠ¶: {poses.shape if poses is not None else 'None'}")

# è°ƒè¯•å¯è§†åŒ–
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 6))
plt.plot([d[0] for d in trajectory_data if d], 
         [d[1] for d in trajectory_data if d], 'b-')
plt.title('çƒä½“è½¨è¿¹')
plt.xlabel('X åæ ‡')
plt.ylabel('Y åæ ‡')
plt.grid(True)
plt.show()
```

#### 3. æ€§èƒ½ç“¶é¢ˆ
```python
# ä½¿ç”¨ profiler
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# è¿è¡Œä»£ç 
result = your_function()

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(20)  # æ‰“å°å‰ 20 ä¸ªæœ€è€—æ—¶çš„å‡½æ•°
```

---

## ğŸ“š å®æˆ˜æ¡ˆä¾‹ç ”ç©¶

### æ¡ˆä¾‹ 1: ä¸“ä¸šè®­ç»ƒåˆ†æ

#### åˆ†ææµç¨‹å›¾

```mermaid
graph TB
    A[æ¯”èµ›è§†é¢‘] --> B[è¿è¡Œåˆ†ææµæ°´çº¿]
    B --> C[çƒä½“æ£€æµ‹]
    B --> D[å§¿æ€æ£€æµ‹]
    B --> E[äº‹ä»¶æ£€æµ‹]
    B --> F[å‡»çƒåˆ†ç±»]
    
    C --> G[å‡»çƒç±»å‹ç»Ÿè®¡]
    D --> G
    E --> G
    F --> G
    
    G --> H[ç”ŸæˆæŠ€æœ¯æŠ¥å‘Š]
    H --> I[åˆ†æç»“æœ]
    
    I --> J[å‡»çƒç±»å‹åˆ†å¸ƒ]
    I --> K[æˆåŠŸç‡åˆ†æ]
    I --> L[æ”¹è¿›å»ºè®®]
    
    J --> M[æ­£æ‰‹é«˜è¿œçƒ 35%]
    J --> N[æ­£æ‰‹æ€çƒ 15%]
    J --> O[åæ‰‹åŠçƒ 12%]
    
    K --> P[92%]
    L --> P
    M --> P
    
    M --> Q[åŠ å¼ºåæ‰‹ç½‘å‰è®­ç»ƒ]
    M --> R[é€‚å½“å¢åŠ æ€çƒé¢‘ç‡]
    M --> S[å°è¯•æ›´å¤šæ ·åŒ–å‡»çƒ]
```

#### èƒŒæ™¯
æŸç¾½æ¯›çƒè¿åŠ¨å‘˜å¸Œæœ›åˆ†æè‡ªå·±åœ¨æ¯”èµ›ä¸­çš„æŠ€æœ¯è¡¨ç°ï¼Œæ‰¾å‡ºéœ€è¦æ”¹è¿›çš„å‡»çƒç±»å‹ã€‚

#### åˆ†ææµç¨‹
```bash
# 1. è¿è¡Œå®Œæ•´åˆ†æ
python run_combined.py \
  --video videos/match_2024.mp4 \
  --result_dir ./results/match_2024 \
  --model models/ball_track_attention.pt \
  --pose_model rtmpose-l \
  --threshold 0.4 \
  --num_frames 5

# 2. æŸ¥çœ‹å‡»çƒç±»å‹ç»Ÿè®¡
python scripts/analyze_strokes.py \
  --stroke_types results/match_2024/match_2024_stroke_types.json

# 3. ç”ŸæˆæŠ€æœ¯æŠ¥å‘Š
python scripts/generate_report.py \
  --data_dir results/match_2024 \
  --output report.pdf
```

#### åˆ†æç»“æœ
| å‡»çƒç±»å‹ | æ¬¡æ•° | å æ¯” | æˆåŠŸç‡ |
|----------|------|------|--------|
| æ­£æ‰‹é«˜è¿œçƒ | 45 | 35% | 92% |
| æ­£æ‰‹æ€çƒ | 20 | 15% | 85% |
| åæ‰‹åŠçƒ | 15 | 12% | 78% |
| æ­£æ‰‹ç½‘å‰çƒ | 10 | 8% | 95% |
| å…¶ä»– | 40 | 30% | 88% |

#### æ”¹è¿›å»ºè®®
1. **åæ‰‹åŠçƒæˆåŠŸç‡è¾ƒä½**ï¼šå»ºè®®åŠ å¼ºåæ‰‹ç½‘å‰è®­ç»ƒ
2. **æ­£æ‰‹æ€çƒä½¿ç”¨é¢‘ç‡é€‚ä¸­**ï¼šå¯ä»¥é€‚å½“å¢åŠ æ€çƒé¢‘ç‡
3. **æ­£æ‰‹é«˜è¿œçƒå æ¯”è¾ƒé«˜**ï¼šå¯ä»¥å°è¯•æ›´å¤šæ ·åŒ–çš„å‡»çƒ

### æ¡ˆä¾‹ 2: æ¯”èµ›æˆ˜æœ¯åˆ†æ

#### èƒŒæ™¯
æ•™ç»ƒå¸Œæœ›åˆ†æåŒæ–¹é€‰æ‰‹çš„æˆ˜æœ¯ç‰¹ç‚¹ï¼Œåˆ¶å®šé’ˆå¯¹æ€§çš„è®­ç»ƒè®¡åˆ’ã€‚

#### åˆ†ææµç¨‹
```bash
# 1. è¿è¡Œåˆ†æ
python run_combined.py \
  --video videos/tournament_final.mp4 \
  --result_dir ./results/tournament_final

# 2. æå–æˆ˜æœ¯æ•°æ®
python scripts/extract_tactics.py \
  --data_dir results/tournament_final \
  --output tactics.csv

# 3. ç”Ÿæˆæˆ˜æœ¯å›¾
python scripts/visualize_tactics.py \
  --tactics tactics.csv \
  --output tactics.png
```

#### æˆ˜æœ¯åˆ†æ
- **é€‰æ‰‹ A**ï¼šåå¥½ä½¿ç”¨æ­£æ‰‹é«˜è¿œçƒå’Œæ€çƒï¼Œè¿›æ”»æ€§å¼º
- **é€‰æ‰‹ B**ï¼šæ“…é•¿åæ‰‹é˜²å®ˆå’Œç½‘å‰çƒï¼Œé˜²å®ˆç¨³å¥
- **å…³é”®å›åˆ**ï¼šç¬¬ 15-20 å›åˆï¼Œé€‰æ‰‹ A è¿ç»­å¾—åˆ†

#### è®­ç»ƒå»ºè®®
1. **é€‰æ‰‹ A**ï¼šåŠ å¼ºåæ‰‹é˜²å®ˆè®­ç»ƒï¼Œæé«˜ç½‘å‰çƒæŠ€æœ¯
2. **é€‰æ‰‹ B**ï¼šæé«˜æ­£æ‰‹è¿›æ”»èƒ½åŠ›ï¼Œå¢åŠ æ€çƒè®­ç»ƒ
3. **åŒæ–¹**ï¼šé’ˆå¯¹å…³é”®å›åˆè¿›è¡Œä¸“é¡¹è®­ç»ƒ

### æ¡ˆä¾‹ 3: ç§‘ç ”æ•°æ®é›†æ„å»º

#### èƒŒæ™¯
ç ”ç©¶äººå‘˜éœ€è¦æ„å»ºç¾½æ¯›çƒå‡»çƒç±»å‹åˆ†ç±»æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒæ–°çš„åˆ†ç±»æ¨¡å‹ã€‚

#### æ•°æ®æ”¶é›†æµç¨‹
```bash
# 1. æ‰¹é‡å¤„ç†è§†é¢‘
for video in videos/*.mp4; do
  python run_combined.py \
    --video "$video" \
    --result_dir "./results/$(basename $video .mp4)" \
    --threshold 0.5 \
    --pose_model rtmpose-m
done

# 2. åˆå¹¶æ•°æ®
python scripts/merge_data.py \
  --input_dir results \
  --output dataset/

# 3. æ•°æ®éªŒè¯
python scripts/validate_dataset.py \
  --dataset_dir dataset

# 4. ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡
python scripts/dataset_stats.py \
  --dataset_dir dataset \
  --output stats.txt
```

#### æ•°æ®é›†ç»Ÿè®¡
| ç±»åˆ« | æ ·æœ¬æ•° | è®­ç»ƒé›† | éªŒè¯é›† | æµ‹è¯•é›† |
|------|--------|--------|--------|--------|
| æ­£æ‰‹é«˜è¿œçƒ | 1200 | 960 | 120 | 120 |
| æ­£æ‰‹æ€çƒ | 800 | 640 | 80 | 80 |
| åæ‰‹åŠçƒ | 600 | 480 | 60 | 60 |
| ... | ... | ... | ... | ... |
| **æ€»è®¡** | **15000** | **12000** | **1500** | **1500** |

#### æ•°æ®è´¨é‡
- **æ ‡æ³¨ä¸€è‡´æ€§**: 98.5%
- **æ•°æ®å®Œæ•´æ€§**: 99.2%
- **æ ·æœ¬å¤šæ ·æ€§**: ä¼˜ç§€

---

## ğŸ“– æœ€ä½³å®è·µæŒ‡å—

### è§†é¢‘å½•åˆ¶æœ€ä½³å®è·µ

#### å½•åˆ¶æµç¨‹å›¾

```mermaid
graph TB
    A[å‡†å¤‡é˜¶æ®µ] --> B[åœºåœ°å‡†å¤‡]
    A --> C[è®¾å¤‡å‡†å¤‡]
    A --> D[ç¯å¢ƒè®¾ç½®]
    
    B --> E[æ ‡å‡†ç¾½æ¯›çƒåœºåœ°]
    B --> F[æ¸…æ´èƒŒæ™¯]
    B --> G[å……è¶³å…‰ç…§]
    
    C --> H[æ‘„åƒæœºé€‰æ‹©]
    C --> I[ä¸‰è„šæ¶è®¾ç½®]
    C --> J[å­˜å‚¨è®¾å¤‡]
    
    D --> K[æœè£…å¯¹æ¯”]
    D --> L[éŸ³é¢‘è®¾å¤‡]
    
    E --> M[å¤šæœºä½è®¾ç½®]
    E --> N[ä¾§é¢è§†è§’]
    E --> O[æ­£é¢è§†è§’]
    E --> P[é«˜è§’åº¦è§†è§’]
    
    H --> Q[å¼€å§‹å½•åˆ¶]
    I --> Q
    J --> Q
    K --> Q
    
    Q --> R[å½•åˆ¶ä¸­]
    R --> S[ç›‘æ§è´¨é‡]
    R --> T[æ£€æŸ¥éŸ³é¢‘]
    
    S --> U[è´¨é‡æ£€æŸ¥é€šè¿‡?]
    T --> U
    S --> V[è´¨é‡æ£€æŸ¥å¤±è´¥]
    T --> V
    
    U --> W[ä¿å­˜è§†é¢‘]
    V --> W
```

#### æ‹æ‘„è§’åº¦
- **ä¾§é¢è§†è§’**: æœ€é€‚åˆåˆ†æå‡»çƒåŠ¨ä½œ
- **æ­£é¢è§†è§’**: é€‚åˆåˆ†æåœºåœ°ç§»åŠ¨
- **é«˜è§’åº¦**: é€‚åˆåˆ†æçƒä½“è½¨è¿¹
- **å¤šæœºä½**: ç»¼åˆåˆ†ææ•ˆæœæœ€ä½³

#### æ‹æ‘„å‚æ•°
| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|----------|------|
| åˆ†è¾¨ç‡ | 1080p æˆ–æ›´é«˜ | ä¿è¯ç»†èŠ‚æ¸…æ™° |
| å¸§ç‡ | 60 FPS æˆ–æ›´é«˜ | æ•æ‰å¿«é€ŸåŠ¨ä½œ |
| æ¯”ç‰¹ç‡ | 10 Mbps æˆ–æ›´é«˜ | ä¿è¯è§†é¢‘è´¨é‡ |
| ç¼–ç  | H.264 æˆ– H.265 | å…¼å®¹æ€§å’Œå‹ç¼©ç‡ |

#### ç¯å¢ƒè¦æ±‚
- **å…‰ç…§**: å……è¶³ä¸”å‡åŒ€ï¼Œé¿å…é˜´å½±
- **èƒŒæ™¯**: ç®€æ´ï¼Œé¿å…å¹²æ‰°
- **åœºåœ°**: æ ‡å‡†ç¾½æ¯›çƒåœºåœ°
- **æœè£…**: ä¸èƒŒæ™¯å½¢æˆå¯¹æ¯”

### æ•°æ®ç®¡ç†æœ€ä½³å®è·µ

#### ç›®å½•ç»“æ„
```
data/
â”œâ”€â”€ raw/              # åŸå§‹è§†é¢‘
â”‚   â”œâ”€â”€ match_001.mp4
â”‚   â”œâ”€â”€ match_002.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ processed/         # å¤„ç†åçš„æ•°æ®
â”‚   â”œâ”€â”€ match_001/
â”‚   â”‚   â”œâ”€â”€ match_001_combined.mp4
â”‚   â”‚   â”œâ”€â”€ match_001_data.csv
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/           # æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ ball_track_attention.pt
â”‚   â””â”€â”€ ...
â””â”€â”€ reports/          # åˆ†ææŠ¥å‘Š
    â”œâ”€â”€ match_001_report.pdf
    â””â”€â”€ ...
```

#### æ•°æ®å¤‡ä»½
```bash
# å®šæœŸå¤‡ä»½
rsync -avz data/ backup/data_$(date +%Y%m%d)/

# ç‰ˆæœ¬æ§åˆ¶
git add data/processed/
git commit -m "Add processed data for match_001"
```

### æ¨¡å‹è®­ç»ƒæœ€ä½³å®è·µ

#### æ•°æ®å¢å¼º
```python
from torchvision import transforms

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                     std=[0.229, 0.224, 0.225])
])
```

#### å­¦ä¹ ç‡è°ƒåº¦
```python
from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau

# ä½™å¼¦é€€ç«
scheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)

# è‡ªé€‚åº”è°ƒæ•´
scheduler = ReduceLROnPlateau(optimizer, mode='min', 
                              factor=0.5, patience=10)
```

#### æ—©åœç­–ç•¥
```python
from torch.utils.data import DataLoader
from torch.optim import Adam
from torch.nn import CrossEntropyLoss

best_val_loss = float('inf')
patience = 10
no_improve = 0

for epoch in range(num_epochs):
    train_loss = train_one_epoch()
    val_loss = validate()
    
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        no_improve = 0
        torch.save(model.state_dict(), 'best_model.pth')
    else:
        no_improve += 1
        if no_improve >= patience:
            print(f"Early stopping at epoch {epoch}")
            break
```

### ä»£ç å¼€å‘æœ€ä½³å®è·µ

#### ä»£ç ç»„ç»‡
```python
# core/
# â”œâ”€â”€ __init__.py
# â”œâ”€â”€ models/
# â”‚   â”œâ”€â”€ __init__.py
# â”‚   â”œâ”€â”€ tracknet.py
# â”‚   â””â”€â”€ bst.py
# â”œâ”€â”€ detectors/
# â”‚   â”œâ”€â”€ __init__.py
# â”‚   â”œâ”€â”€ ball_detect.py
# â”‚   â””â”€â”€ pose_detect.py
# â””â”€â”€ utils/
#     â”œâ”€â”€ __init__.py
#     â”œâ”€â”€ metrics.py
#     â””â”€â”€ visualization.py
```

#### å•å…ƒæµ‹è¯•
```python
import pytest
import numpy as np

def test_kalman_filter():
    kf = KalmanFilter(dt=1.0, process_noise=1.0, measurement_noise=10.0)
    kf.init(0, 0)
    
    # é¢„æµ‹
    predicted = kf.predict()
    assert predicted is not None
    assert len(predicted) == 2
    
    # æ›´æ–°
    updated = kf.update([1, 1])
    assert updated is not None
    assert len(updated) == 2

def test_event_detection():
    trajectory = [(100, 200), (150, 250), (200, 300)]
    detector = EventDetector(trajectory)
    hits, players = detector.detect_hits()
    
    assert len(hits) > 0
    assert all(isinstance(h, int) for h in hits)
    assert all(p in [1, 2] for p in players)
```

#### æ–‡æ¡£å­—ç¬¦ä¸²
```python
def detect_hits(self, fps=25, prominence=2, angle_threshold=30, 
              velocity_threshold=3, min_frame_gap=13, 
              min_continuation_frames=5, min_movement_threshold=20):
    """
    æ£€æµ‹å‡»çƒäº‹ä»¶ã€‚
    
    Args:
        fps (int): è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤ 25
        prominence (float): å³°å€¼æ˜¾è‘—æ€§ï¼Œé»˜è®¤ 2.0
        angle_threshold (float): è§’åº¦å˜åŒ–é˜ˆå€¼ï¼ˆåº¦ï¼‰ï¼Œé»˜è®¤ 30
        velocity_threshold (float): é€Ÿåº¦é˜ˆå€¼ï¼Œé»˜è®¤ 3.0
        min_frame_gap (int): æœ€å°å¸§é—´éš”ï¼Œé»˜è®¤ 13
        min_continuation_frames (int): æœ€å°è¿ç»­å¸§æ•°ï¼Œé»˜è®¤ 5
        min_movement_threshold (float): æœ€å°ç§»åŠ¨é˜ˆå€¼ï¼Œé»˜è®¤ 20.0
    
    Returns:
        tuple: (hit_frames, hit_players)
            - hit_frames (list[int]): å‡»çƒå¸§ç´¢å¼•åˆ—è¡¨
            - hit_players (list[int]): å‡»çƒçƒå‘˜ç¼–å·åˆ—è¡¨ï¼ˆ1 æˆ– 2ï¼‰
    
    Examples:
        >>> detector = EventDetector(trajectory_data, poses)
        >>> hits, players = detector.detect_hits(fps=30, prominence=1.5)
        >>> print(f"æ£€æµ‹åˆ° {len(hits)} æ¬¡å‡»çƒ")
        æ£€æµ‹åˆ° 20 æ¬¡å‡»çƒ
    """
    pass
```

---

## ï¿½ æ€§èƒ½æŒ‡æ ‡

### æ£€æµ‹æ€§èƒ½

#### çƒä½“æ£€æµ‹

| æŒ‡æ ‡ | æ•°å€¼ | æµ‹è¯•æ¡ä»¶ |
|------|------|----------|
| ç²¾ç¡®ç‡ | 95.2% | æ ‡å‡†æµ‹è¯•é›† |
| å¬å›ç‡ | 93.8% | æ ‡å‡†æµ‹è¯•é›† |
| F1 åˆ†æ•° | 94.5% | æ ‡å‡†æµ‹è¯•é›† |
| å¤„ç†é€Ÿåº¦ | 120 FPS | RTX 3090, CUDA 11.8 |
| å†…å­˜å ç”¨ | 2.1 GB | RTX 3090 |

#### å§¿æ€æ£€æµ‹

| æŒ‡æ ‡ | æ•°å€¼ | æµ‹è¯•æ¡ä»¶ |
|------|------|----------|
| COCO mAP | 0.78 | COCO éªŒè¯é›† |
| AR@10 | 0.85 | COCO éªŒè¯é›† |
| AR@20 | 0.92 | COCO éªŒè¯é›† |
| å¤„ç†é€Ÿåº¦ | 45 FPS | RTX 3090, rtmpose-m |
| å†…å­˜å ç”¨ | 3.5 GB | RTX 3090 |

#### åœºåœ°æ£€æµ‹

| æŒ‡æ ‡ | æ•°å€¼ | æµ‹è¯•æ¡ä»¶ |
|------|------|----------|
| å…³é”®ç‚¹å‡†ç¡®ç‡ | 96.5% | æ ‡å‡†æµ‹è¯•é›† |
| è¾¹ç•Œå‚æ•°è¯¯å·® | 2.3 åƒç´  | æ ‡å‡†æµ‹è¯•é›† |
| å¤„ç†é€Ÿåº¦ | 30 FPS | RTX 3090 |
| å†…å­˜å ç”¨ | 1.8 GB | RTX 3090 |

#### å‡»çƒäº‹ä»¶æ£€æµ‹

| æŒ‡æ ‡ | æ•°å€¼ | æµ‹è¯•æ¡ä»¶ |
|------|------|----------|
| å¬å›ç‡ | 91.2% | æ ‡å‡†æµ‹è¯•é›† |
| ç²¾ç¡®ç‡ | 88.5% | æ ‡å‡†æµ‹è¯•é›† |
| F1 åˆ†æ•° | 89.8% | æ ‡å‡†æµ‹è¯•é›† |
| è¯¯æ£€ç‡ | 8.3% | æ ‡å‡†æµ‹è¯•é›† |
| æ¼æ£€ç‡ | 11.5% | æ ‡å‡†æµ‹è¯•é›† |

#### å‡»çƒç±»å‹åˆ†ç±»

| æŒ‡æ ‡ | æ•°å€¼ | æµ‹è¯•æ¡ä»¶ |
|------|------|----------|
| å‡†ç¡®ç‡ | 86.3% | Shuttleset æµ‹è¯•é›† |
| Top-3 å‡†ç¡®ç‡ | 94.7% | Shuttleset æµ‹è¯•é›† |
| Top-5 å‡†ç¡®ç‡ | 97.2% | Shuttleset æµ‹è¯•é›† |
| å¤„ç†é€Ÿåº¦ | 80 å‡»çƒ/ç§’ | RTX 3090 |
| å†…å­˜å ç”¨ | 4.2 GB | RTX 3090 |

### ç³»ç»Ÿæ€§èƒ½

#### å¤„ç†é€Ÿåº¦

| è§†é¢‘é•¿åº¦ | å¤„ç†æ—¶é—´ | å¹³å‡é€Ÿåº¦ |
|----------|----------|----------|
| 1 åˆ†é’Ÿ | 2.5 åˆ†é’Ÿ | 24 FPS |
| 5 åˆ†é’Ÿ | 11.8 åˆ†é’Ÿ | 25 FPS |
| 10 åˆ†é’Ÿ | 23.5 åˆ†é’Ÿ | 26 FPS |
| 30 åˆ†é’Ÿ | 68.2 åˆ†é’Ÿ | 24 FPS |

#### èµ„æºå ç”¨

| ç»„ä»¶ | CPU å ç”¨ | GPU å ç”¨ | å†…å­˜å ç”¨ |
|------|----------|----------|----------|
| çƒä½“æ£€æµ‹ | 15% | 25% | 2.1 GB |
| å§¿æ€æ£€æµ‹ | 25% | 35% | 3.5 GB |
| åœºåœ°æ£€æµ‹ | 10% | 15% | 1.8 GB |
| äº‹ä»¶æ£€æµ‹ | 5% | 5% | 0.5 GB |
| å‡»çƒåˆ†ç±» | 8% | 20% | 4.2 GB |
| å¯è§†åŒ– | 20% | 30% | 2.8 GB |
| **æ€»è®¡** | **83%** | **130%** | **14.9 GB** |

### ç¡¬ä»¶è¦æ±‚

#### æœ€ä½é…ç½®

- CPU: Intel Core i5-8400
- GPU: NVIDIA GTX 1060 6GB
- å†…å­˜: 8GB DDR4
- å­˜å‚¨: 20GB SSD
- æ“ä½œç³»ç»Ÿ: Windows 10 / Ubuntu 18.04

#### æ¨èé…ç½®

- CPU: Intel Core i7-10700K
- GPU: NVIDIA RTX 3060 12GB
- å†…å­˜: 16GB DDR4
- å­˜å‚¨: 50GB NVMe SSD
- æ“ä½œç³»ç»Ÿ: Windows 11 / Ubuntu 20.04

#### é«˜æ€§èƒ½é…ç½®

- CPU: Intel Core i9-11900K
- GPU: NVIDIA RTX 3090 24GB
- å†…å­˜: 32GB DDR4
- å­˜å‚¨: 100GB NVMe SSD
- æ“ä½œç³»ç»Ÿ: Windows 11 / Ubuntu 22.04

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
TrackNetV3_Attention/
â”œâ”€â”€ core/                                    # æ ¸å¿ƒç®—æ³•æ¨¡å—
â”‚   â”œâ”€â”€ TrackNetAttention.py                 # TrackNetV3 + CBAM æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ Conv                            # å·ç§¯å—ï¼ˆConv+BN+ReLUï¼‰
â”‚   â”‚   â”œâ”€â”€ ChannelAttention                # é€šé“æ³¨æ„åŠ›
â”‚   â”‚   â”œâ”€â”€ SpatialAttention                 # ç©ºé—´æ³¨æ„åŠ›
â”‚   â”‚   â”œâ”€â”€ CBAM                            # CBAM æ¨¡å—
â”‚   â”‚   â””â”€â”€ TrackNetAttention              # ä¸»ç½‘ç»œç±»
â”‚   â”‚
â”‚   â”œâ”€â”€ ball_detect.py                     # ç¾½æ¯›çƒæ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ ball_detect()                   # ä¸»æ£€æµ‹å‡½æ•°
â”‚   â”‚   â””â”€â”€ __main__()                     # å‘½ä»¤è¡Œæ¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ pose_detect.py                     # MMPose å§¿æ€æ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ PoseDetector                    # å§¿æ€æ£€æµ‹å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ detect_video()                  # è§†é¢‘æ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ save_poses()                   # ä¿å­˜å§¿æ€
â”‚   â”‚   â”œâ”€â”€ load_poses()                   # åŠ è½½å§¿æ€
â”‚   â”‚   â”œâ”€â”€ visualize_poses()              # å¯è§†åŒ–å§¿æ€
â”‚   â”‚   â””â”€â”€ detect_poses_video()           # å‘½ä»¤è¡Œæ¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ court_detect.py                    # åœºåœ°æ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ CourtDetector                   # åœºåœ°æ£€æµ‹å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ get_court_info()               # è·å–åœºåœ°ä¿¡æ¯
â”‚   â”‚   â”œâ”€â”€ get_court_boundary_params()     # è·å–è¾¹ç•Œå‚æ•°
â”‚   â”‚   â”œâ”€â”€ get_partitioned_keypoints()     # è·å–åˆ†åŒºå…³é”®ç‚¹
â”‚   â”‚   â”œâ”€â”€ draw_court()                  # ç»˜åˆ¶åœºåœ°
â”‚   â”‚   â””â”€â”€ player_detection()             # çƒå‘˜æ£€æµ‹
â”‚   â”‚
â”‚   â”œâ”€â”€ net_detect.py                      # çƒç½‘æ£€æµ‹
â”‚   â”‚   â””â”€â”€ NetDetector                    # çƒç½‘æ£€æµ‹å™¨ç±»
â”‚   â”‚
â”‚   â”œâ”€â”€ event_detect.py                    # å‡»çƒäº‹ä»¶æ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ EventDetector                   # äº‹ä»¶æ£€æµ‹å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ detect_hits()                  # æ£€æµ‹å‡»çƒ
â”‚   â”‚   â”œâ”€â”€ _calculate_angle()             # è®¡ç®—è§’åº¦
â”‚   â”‚   â”œâ”€â”€ _filter_hits_by_pose()         # å§¿æ€è¿‡æ»¤
â”‚   â”‚   â”œâ”€â”€ _validate_hit_continuation()    # è¿ç»­æ€§éªŒè¯
â”‚   â”‚   â”œâ”€â”€ _merge_consecutive_hits()      # åˆå¹¶è¿ç»­å‡»çƒ
â”‚   â”‚   â”œâ”€â”€ _detect_landing_frame()        # æ£€æµ‹è½åœ°å¸§
â”‚   â”‚   â””â”€â”€ save_hit_events()             # ä¿å­˜å‡»çƒäº‹ä»¶
â”‚   â”‚
â”‚   â”œâ”€â”€ stroke_classify.py                 # BST å‡»çƒåˆ†ç±»
â”‚   â”‚   â”œâ”€â”€ StrokeClassifier                # å‡»çƒåˆ†ç±»å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ classify_hit()                 # åˆ†ç±»å•ä¸ªå‡»çƒ
â”‚   â”‚   â”œâ”€â”€ classify_hits()                # åˆ†ç±»å¤šä¸ªå‡»çƒ
â”‚   â”‚   â”œâ”€â”€ prepare_hit_segment()          # å‡†å¤‡å‡»çƒç‰‡æ®µ
â”‚   â”‚   â”œâ”€â”€ get_stroke_type_name()         # è·å–å‡»çƒç±»å‹åç§°
â”‚   â”‚   â”œâ”€â”€ get_stroke_type_name_en()     # è·å–è‹±æ–‡åç§°
â”‚   â”‚   â”œâ”€â”€ save_stroke_results()          # ä¿å­˜åˆ†ç±»ç»“æœ
â”‚   â”‚   â””â”€â”€ create_classifier()            # åˆ›å»ºåˆ†ç±»å™¨
â”‚   â”‚
â”‚   â”œâ”€â”€ person_tracker.py                  # äººå‘˜è·Ÿè¸ª
â”‚   â”‚   â””â”€â”€ track_poses()                  # è·Ÿè¸ªå§¿æ€
â”‚   â”‚
â”‚   â”œâ”€â”€ denoise.py                        # è½¨è¿¹å»å™ª
â”‚   â”‚   â”œâ”€â”€ smooth()                        # ä¸»å¹³æ»‘å‡½æ•°
â”‚   â”‚   â””â”€â”€ __main__()                      # å‘½ä»¤è¡Œæ¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ kalman_filter.py                  # å¡å°”æ›¼æ»¤æ³¢å™¨
â”‚   â”‚   â”œâ”€â”€ KalmanFilter                    # å¡å°”æ›¼æ»¤æ³¢å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ KalmanTrajectorySmoother        # è½¨è¿¹å¹³æ»‘å™¨ç±»
â”‚   â”‚   â”œâ”€â”€ init()                          # åˆå§‹åŒ–
â”‚   â”‚   â”œâ”€â”€ predict()                       # é¢„æµ‹
â”‚   â”‚   â””â”€â”€ update()                        # æ›´æ–°
â”‚   â”‚
â”‚   â”œâ”€â”€ visualize_combined.py              # ç»¼åˆå¯è§†åŒ–
â”‚   â”‚   â”œâ”€â”€ visualize_combined()           # ä¸»å¯è§†åŒ–å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ create_combined_visualization() # åˆ›å»ºå¯è§†åŒ–
â”‚   â”‚   â”œâ”€â”€ _extract_court_zones()        # æå–åœºåœ°åˆ†åŒº
â”‚   â”‚   â”œâ”€â”€ _highlight_player_zones()      # é«˜äº®çƒå‘˜åŒºåŸŸ
â”‚   â”‚   â”œâ”€â”€ _calculate_ball_speeds()     # è®¡ç®—çƒé€Ÿ
â”‚   â”‚   â”œâ”€â”€ _calculate_speed_thresholds()  # è®¡ç®—é€Ÿåº¦é˜ˆå€¼
â”‚   â”‚   â”œâ”€â”€ _get_speed_color()           # è·å–é€Ÿåº¦é¢œè‰²
â”‚   â”‚   â””â”€â”€ load_ball_positions()        # åŠ è½½çƒä½“ä½ç½®
â”‚   â”‚
â”‚   â”œâ”€â”€ export_to_csv.py                  # æ•°æ®å¯¼å‡º
â”‚   â”‚   â””â”€â”€ export_to_csv()              # å¯¼å‡º CSV
â”‚   â”‚
â”‚   â”œâ”€â”€ court_based_assigner.py          # åŸºäºåœºåœ°çš„çƒå‘˜åˆ†é…
â”‚   â”‚   â””â”€â”€ CourtBasedPlayerAssigner       # çƒå‘˜åˆ†é…å™¨ç±»
â”‚   â”‚
â”‚   â””â”€â”€ utils.py                          # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ read_json()                    # è¯»å– JSON
â”‚       â”œâ”€â”€ write_json()                   # å†™å…¥ JSON
â”‚       â””â”€â”€ ...                           # å…¶ä»–å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ ui_pyside6/                          # å›¾å½¢ç•Œé¢
â”‚   â”œâ”€â”€ main.py                          # ä¸»çª—å£
â”‚   â”‚   â”œâ”€â”€ MainWindow                    # ä¸»çª—å£ç±»
â”‚   â”‚   â”œâ”€â”€ _build_ui()                   # æ„å»º UI
â”‚   â”‚   â”œâ”€â”€ _connect()                    # è¿æ¥ä¿¡å·
â”‚   â”‚   â”œâ”€â”€ _start_pipeline()             # å¯åŠ¨æµæ°´çº¿
â”‚   â”‚   â”œâ”€â”€ _stop_pipeline()              # åœæ­¢æµæ°´çº¿
â”‚   â”‚   â”œâ”€â”€ _load_outputs()              # åŠ è½½è¾“å‡º
â”‚   â”‚   â”œâ”€â”€ _update_overview()           # æ›´æ–°æ¦‚è§ˆ
â”‚   â”‚   â”œâ”€â”€ _update_players()            # æ›´æ–°çƒå‘˜åˆ†æ
â”‚   â”‚   â”œâ”€â”€ _update_distributions()       # æ›´æ–°åˆ†å¸ƒåˆ†æ
â”‚   â”‚   â””â”€â”€ ...                           # å…¶ä»–æ–¹æ³•
â”‚   â”‚
â”‚   â”œâ”€â”€ widgets/                         # è‡ªå®šä¹‰ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ video_player.py               # è§†é¢‘æ’­æ”¾å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoPlayer               # æ’­æ”¾å™¨ç±»
â”‚   â”‚   â”‚   â”œâ”€â”€ open()                   # æ‰“å¼€è§†é¢‘
â”‚   â”‚   â”‚   â”œâ”€â”€ play()                   # æ’­æ”¾
â”‚   â”‚   â”‚   â”œâ”€â”€ pause()                  # æš‚åœ
â”‚   â”‚   â”‚   â”œâ”€â”€ stop()                   # åœæ­¢
â”‚   â”‚   â”‚   â”œâ”€â”€ seek()                   # è·³è½¬
â”‚   â”‚   â”‚   â””â”€â”€ info()                   # è·å–ä¿¡æ¯
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ data_models.py               # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ DataFrameModel            # æ•°æ®æ¡†æ¨¡å‹
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ simple_plot.py               # å›¾è¡¨ç»„ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ SimpleLinePlot           # ç®€å•çº¿å›¾
â”‚   â”‚   â”‚   â”œâ”€â”€ DensityBubbleMap         # å¯†åº¦æ°”æ³¡å›¾
â”‚   â”‚   â”‚   â”œâ”€â”€ MetricCard              # æŒ‡æ ‡å¡ç‰‡
â”‚   â”‚   â”‚   â”œâ”€â”€ ProDistributionChart    # æ¦‚ç‡åˆ†å¸ƒå›¾
â”‚   â”‚   â”‚   â”œâ”€â”€ SimpleBarChart          # ç®€å•æŸ±çŠ¶å›¾
â”‚   â”‚   â”‚   â”œâ”€â”€ TerritoryScatterPlot    # é¢†åœŸæ•£ç‚¹å›¾
â”‚   â”‚   â”‚   â””â”€â”€ TimelineMarkers         # æ—¶é—´è½´æ ‡è®°
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pipeline_worker.py           # æµæ°´çº¿å·¥ä½œå™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ PipelineWorker           # å·¥ä½œå™¨ç±»
â”‚   â”‚   â”‚   â”œâ”€â”€ PipelineConfig          # é…ç½®ç±»
â”‚   â”‚   â”‚   â””â”€â”€ WorkerThread           # å·¥ä½œçº¿ç¨‹ç±»
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ pipeline_runner.py          # æµæ°´çº¿è¿è¡Œå™¨
â”‚   â”‚
â”‚   â””â”€â”€ match_review/                   # æ¯”èµ›å¤ç›˜çª—å£
â”‚       â”œâ”€â”€ review_window.py             # å¤ç›˜çª—å£
â”‚       â”œâ”€â”€ panels.py                  # é¢æ¿ç»„ä»¶
â”‚       â”œâ”€â”€ engine.py                  # å¤ç›˜å¼•æ“
â”‚       â””â”€â”€ arena.py                   # å¤ç›˜ç«æŠ€åœº
â”‚
â”œâ”€â”€ models/                              # æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ ball_track_attention.pt       # TrackNetV3 æƒé‡
â”‚   â”œâ”€â”€ court_kpRCNN.pth            # åœºåœ°æ£€æµ‹æƒé‡
â”‚   â”œâ”€â”€ net_kpRCNN.pth               # çƒç½‘æ£€æµ‹æƒé‡
â”‚   â””â”€â”€ bst/                            # BST æ¨¡å‹
â”‚       â”œâ”€â”€ shuttleset_35classes/    # 35ç±»æ¨¡å‹
â”‚       â”œâ”€â”€ badDB_6classes/          # 6ç±»æ¨¡å‹
â”‚       â””â”€â”€ tenniSet_6classes/       # 6ç±»æ¨¡å‹
â”‚
â”œâ”€â”€ videos/                             # ç¤ºä¾‹è§†é¢‘
â”‚   â”œâ”€â”€ test2.mp4
â”‚   â””â”€â”€ test6.mp4
â”‚
â”œâ”€â”€ results/                            # è¾“å‡ºç»“æœ
â”‚   â””â”€â”€ <è§†é¢‘å>/
â”‚       â”œâ”€â”€ *_combined.mp4              # ç»¼åˆå¯è§†åŒ–è§†é¢‘
â”‚       â”œâ”€â”€ *_data.csv                 # å®Œæ•´æ•°æ®è¡¨
â”‚       â”œâ”€â”€ *_hit_events.json          # å‡»çƒäº‹ä»¶åˆ—è¡¨
â”‚       â”œâ”€â”€ *_stroke_types.json        # å‡»çƒç±»å‹åˆ†ç±»
â”‚       â”œâ”€â”€ *_poses.npy               # å§¿æ€å…³é”®ç‚¹æ•°ç»„
â”‚       â”œâ”€â”€ loca_info/               # åŸå§‹çƒä½“ä½ç½®
â”‚       â””â”€â”€ loca_info_denoise/       # å»å™ªåçƒä½“ä½ç½®
â”‚
â”œâ”€â”€ run_combined.py                     # ä¸»æµæ°´çº¿è„šæœ¬
â”œâ”€â”€ requirements.txt                     # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ setup.py                           # å®‰è£…è„šæœ¬
â”œâ”€â”€ README.md                          # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ LICENSE                            # è®¸å¯è¯
```

---

## ğŸ“„ è¾“å‡ºæ–‡ä»¶è¯´æ˜

### CSV æ•°æ®è¡¨å­—æ®µè¯¦è§£

#### æ—¶é—´æˆ³å­—æ®µ
- `time_seconds`: æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
- `frame`: å¸§ç´¢å¼•

#### çƒä½“å­—æ®µ
- `ball_x`: çƒä½“ X åæ ‡ï¼ˆåŸå§‹ï¼‰
- `ball_y`: çƒä½“ Y åæ ‡ï¼ˆåŸå§‹ï¼‰
- `ball_speed`: çƒä½“é€Ÿåº¦ï¼ˆåƒç´ /ç§’ï¼‰
- `ball_visible`: çƒä½“å¯è§æ€§ï¼ˆ0/1ï¼‰

#### å»å™ªçƒä½“å­—æ®µ
- `ball_denoise_x`: çƒä½“ X åæ ‡ï¼ˆå»å™ªï¼‰
- `ball_denoise_y`: çƒä½“ Y åæ ‡ï¼ˆå»å™ªï¼‰
- `ball_denoise_visible`: çƒä½“å¯è§æ€§ï¼ˆå»å™ªï¼Œ0/1ï¼‰

#### çƒå‘˜é€Ÿåº¦å­—æ®µ
- `p0_speed`: çƒå‘˜ 0 é€Ÿåº¦ï¼ˆåƒç´ /ç§’ï¼‰
- `p1_speed`: çƒå‘˜ 1 é€Ÿåº¦ï¼ˆåƒç´ /ç§’ï¼‰

#### çƒå‘˜å§¿æ€å­—æ®µï¼ˆçƒå‘˜ 0ï¼‰
- `p0_joint0_x` ~ `p0_joint16_x`: 17 ä¸ªå…³é”®ç‚¹çš„ X åæ ‡
- `p0_joint0_y` ~ `p0_joint16_y`: 17 ä¸ªå…³é”®ç‚¹çš„ Y åæ ‡

#### çƒå‘˜å§¿æ€å­—æ®µï¼ˆçƒå‘˜ 1ï¼‰
- `p1_joint0_x` ~ `p1_joint16_x`: 17 ä¸ªå…³é”®ç‚¹çš„ X åæ ‡
- `p1_joint0_y` ~ `p1_joint16_y`: 17 ä¸ªå…³é”®ç‚¹çš„ Y åæ ‡

#### å‡»çƒå­—æ®µ
- `is_hit`: æ˜¯å¦ä¸ºå‡»çƒå¸§ï¼ˆ0/1ï¼‰
- `cumulative_hit_count`: ç´¯è®¡å‡»çƒæ•°

### å‡»çƒäº‹ä»¶ JSON æ ¼å¼

```json
[
  {
    "frame": 123,           # å¸§ç´¢å¼•
    "player": 1            # çƒå‘˜ç¼–å·ï¼ˆ1 æˆ– 2ï¼‰
  },
  {
    "frame": 156,
    "player": 0
  }
]
```

### å‡»çƒç±»å‹ JSON æ ¼å¼

```json
[
  {
    "frame": 123,                    # å¸§ç´¢å¼•
    "player": 1,                     # çƒå‘˜ç¼–å·
    "stroke_type_id": 4,             # å‡»çƒç±»å‹ IDï¼ˆ0-34ï¼‰
    "stroke_type_name": "æ­£æ‰‹æ€çƒ",   # ä¸­æ–‡åç§°
    "stroke_type_name_en": "forehand_smash"  # è‹±æ–‡åç§°
  }
]
```

### å§¿æ€ Numpy æ•°ç»„æ ¼å¼

```python
# å½¢çŠ¶: (å¸§æ•°, 2äºº, 17å…³é”®ç‚¹, 2åæ ‡)
poses = np.load('video_poses.npy')

# è®¿é—®ç¤ºä¾‹
frame_idx = 100
player_idx = 0
joint_idx = 5  # å·¦è‚©
x = poses[frame_idx, player_idx, joint_idx, 0]
y = poses[frame_idx, player_idx, joint_idx, 1]
```

### ç»¼åˆå¯è§†åŒ–è§†é¢‘

- æ ¼å¼ï¼šMP4
- ç¼–ç å™¨ï¼šmp4v
- åˆ†è¾¨ç‡ï¼šä¸è¾“å…¥è§†é¢‘ç›¸åŒ
- å¸§ç‡ï¼šä¸è¾“å…¥è§†é¢‘ç›¸åŒ
- å†…å®¹ï¼šçƒä½“è½¨è¿¹ + çƒå‘˜éª¨æ¶ + åœºåœ°è¾¹ç•Œ + å‡»çƒäº‹ä»¶ + å‡»çƒç±»å‹

---

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### TrackNetV3 å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | å½±å“ |
|------|------|--------|------|------|
| `--num_frames` | è¾“å…¥å¸§æ•° | 3 | 1-9 | æ£€æµ‹ç²¾åº¦ vs é€Ÿåº¦ |
| `--threshold` | æ£€æµ‹é˜ˆå€¼ | 0.5 | 0.0-1.0 | å¬å›ç‡ vs ç²¾ç¡®ç‡ |
| `--model` | æ¨¡å‹è·¯å¾„ | models/ball_track_attention.pt | - | æ£€æµ‹ç²¾åº¦ |

**å‚æ•°è°ƒä¼˜å»ºè®®**ï¼š
- æé«˜å¬å›ç‡ï¼šé™ä½ `--threshold`ï¼ˆå¦‚ 0.3ï¼‰
- æé«˜ç²¾ç¡®ç‡ï¼šæé«˜ `--threshold`ï¼ˆå¦‚ 0.7ï¼‰
- æé«˜ç²¾åº¦ï¼šå¢åŠ  `--num_frames`ï¼ˆå¦‚ 5ï¼‰
- æé«˜é€Ÿåº¦ï¼šå‡å°‘ `--num_frames`ï¼ˆå¦‚ 1ï¼‰

### MMPose å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | æ¨èå€¼ | å½±å“ |
|------|------|--------|------|--------|------|
| `--pose_model` | å§¿æ€æ¨¡å‹ | rtmpose-m | t/s/m/l | rtmpose-m | é€Ÿåº¦ vs ç²¾åº¦ |
| `--device` | è®¾å¤‡ç±»å‹ | cuda | cuda/cpu | cuda | å¤„ç†é€Ÿåº¦ |

**æ¨¡å‹é€‰æ‹©å»ºè®®**ï¼š
- å®æ—¶åº”ç”¨ï¼šrtmpose-t æˆ– rtmpose-s
- å¹³è¡¡åœºæ™¯ï¼šrtmpose-mï¼ˆæ¨èï¼‰
- ç¦»çº¿åˆ†æï¼šrtmpose-l

### åœºåœ°æ£€æµ‹å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | æ¨èå€¼ | å½±å“ |
|------|------|--------|------|--------|------|
| `--use_court_detection` | å¯ç”¨åœºåœ°æ£€æµ‹ | True | - | True | çƒå‘˜åˆ†é…ç²¾åº¦ |
| `--court_model` | åœºåœ°æ£€æµ‹æ¨¡å‹ | models/court_kpRCNN.pth | - | - | åœºåœ°æ£€æµ‹ç²¾åº¦ |
| `--court_detection_interval` | åœºåœ°æ£€æµ‹é—´éš” | 30 | 1-300 | 15-60 | å¤„ç†é€Ÿåº¦ vs ç²¾åº¦ |

**æ£€æµ‹é—´éš”å»ºè®®**ï¼š
- é«˜ç²¾åº¦ï¼š15-30 å¸§
- å¹³è¡¡ï¼š30-60 å¸§ï¼ˆæ¨èï¼‰
- é«˜é€Ÿåº¦ï¼š60-120 å¸§

### å¯è§†åŒ–å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | æ¨èå€¼ | å½±å“ |
|------|------|--------|------|--------|------|
| `--traj_len` | è½¨è¿¹æ˜¾ç¤ºé•¿åº¦ | 10 | 1-60 | 10-20 | å¯è§†åŒ–æ•ˆæœ |

### äº‹ä»¶æ£€æµ‹å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | æ¨èå€¼ | å½±å“ |
|------|------|--------|------|--------|------|
| `--prominence` | å³°å€¼æ˜¾è‘—æ€§ | 1.0 | 0.1-10.0 | 0.5-2.0 | äº‹ä»¶æ£€æµ‹æ•æ„Ÿåº¦ |
| `--angle_threshold` | è§’åº¦å˜åŒ–é˜ˆå€¼ | 15 | 5-45 | 10-20 | äº‹ä»¶æ£€æµ‹å‡†ç¡®åº¦ |
| `--min_frame_gap` | æœ€å°å¸§é—´éš” | 5 | 1-30 | 3-10 | äº‹ä»¶åˆå¹¶ç­–ç•¥ |
| `--min_continuation_frames` | æœ€å°è¿ç»­å¸§æ•° | 2 | 1-10 | 2-5 | äº‹ä»¶éªŒè¯ä¸¥æ ¼åº¦ |
| `--min_movement_threshold` | æœ€å°ç§»åŠ¨é˜ˆå€¼ | 5 | 1-50 | 3-10 | äº‹ä»¶éªŒè¯ä¸¥æ ¼åº¦ |

**å‚æ•°è°ƒä¼˜å»ºè®®**ï¼š
- æé«˜å¬å›ç‡ï¼šé™ä½ `--prominence`ï¼ˆå¦‚ 0.5ï¼‰
- æé«˜ç²¾ç¡®ç‡ï¼šæé«˜ `--prominence`ï¼ˆå¦‚ 2.0ï¼‰
- å‡å°‘è¯¯æ£€ï¼šæé«˜ `--angle_threshold`ï¼ˆå¦‚ 20ï¼‰
- å‡å°‘æ¼æ£€ï¼šé™ä½ `--angle_threshold`ï¼ˆå¦‚ 10ï¼‰
- ä¸¥æ ¼éªŒè¯ï¼šæé«˜ `--min_continuation_frames`ï¼ˆå¦‚ 5ï¼‰
- å®½æ¾éªŒè¯ï¼šé™ä½ `--min_continuation_frames`ï¼ˆå¦‚ 1ï¼‰

### BST åˆ†ç±»å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | èŒƒå›´ | æ¨èå€¼ | å½±å“ |
|------|------|--------|------|--------|------|
| `--dataset` | æ•°æ®é›†ç±»å‹ | shuttleset | shuttleset/badDB/tenniSet | shuttleset | åˆ†ç±»ç±»åˆ«æ•° |
| `--seq_len` | åºåˆ—é•¿åº¦ | 100 | 50-200 | 100 | æ—¶åºç‰¹å¾æå– |

**æ•°æ®é›†é€‰æ‹©å»ºè®®**ï¼š
- 35 ç±»åˆ†ç±»ï¼šshuttlesetï¼ˆæ¨èï¼‰
- 6 ç±»åˆ†ç±»ï¼šbadDB æˆ– tenniSet

---

## ğŸ¯ åº”ç”¨åœºæ™¯

### ä¸“ä¸šè®­ç»ƒ

#### è¿åŠ¨å‘˜æŠ€æœ¯åŠ¨ä½œåˆ†æ
- **å‡»çƒç±»å‹ç»Ÿè®¡**ï¼šè‡ªåŠ¨ç»Ÿè®¡å„ç±»å‡»çƒçš„ä½¿ç”¨é¢‘ç‡
- **å‡»çƒä½ç½®åˆ†æ**ï¼šåˆ†æå‡»çƒä½ç½®åˆ†å¸ƒ
- **å‡»çƒé€Ÿåº¦åˆ†æ**ï¼šåˆ†æå‡»çƒé€Ÿåº¦å˜åŒ–
- **æŠ€æœ¯å¼±ç‚¹è¯†åˆ«**ï¼šè¯†åˆ«éœ€è¦æ”¹è¿›çš„æŠ€æœ¯åŠ¨ä½œ

#### æ•™ç»ƒå‘˜æ•™å­¦å·¥å…·
- **åŠ¨ä½œç¤ºèŒƒå¯¹æ¯”**ï¼šå¯¹æ¯”æ ‡å‡†åŠ¨ä½œå’Œå®é™…åŠ¨ä½œ
- **å®æ—¶åé¦ˆ**ï¼šæä¾›å³æ—¶çš„æŠ€æœ¯åé¦ˆ
- **è®­ç»ƒè®¡åˆ’åˆ¶å®š**ï¼šåŸºäºæ•°æ®åˆ†æåˆ¶å®šä¸ªæ€§åŒ–è®­ç»ƒè®¡åˆ’
- **è¿›æ­¥è·Ÿè¸ª**ï¼šè·Ÿè¸ªè¿åŠ¨å‘˜çš„æŠ€æœ¯è¿›æ­¥

### æ¯”èµ›åˆ†æ

#### å®æ—¶æ¯”èµ›åˆ†æ
- **å®æ—¶æ•°æ®ç»Ÿè®¡**ï¼šæ¯”èµ›è¿›è¡Œä¸­çš„å®æ—¶æ•°æ®æ›´æ–°
- **æˆ˜æœ¯åˆ†æ**ï¼šåˆ†æåŒæ–¹æˆ˜æœ¯ç‰¹ç‚¹
- **å…³é”®å›åˆè¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ«å…³é”®å›åˆ
- **æ¯”åˆ†é¢„æµ‹**ï¼šåŸºäºæ•°æ®åˆ†æé¢„æµ‹æ¯”èµ›èµ°åŠ¿

#### èµ›åæˆ˜æœ¯åˆ†æ
- **å®Œæ•´æ¯”èµ›å›é¡¾**ï¼šå®Œæ•´çš„æ¯”èµ›æ•°æ®è®°å½•
- **æˆ˜æœ¯å¯¹æ¯”**ï¼šå¯¹æ¯”ä¸åŒæˆ˜æœ¯çš„æ•ˆæœ
- **é€‰æ‰‹è¡¨ç°è¯„ä¼°**ï¼šå…¨é¢çš„é€‰æ‰‹è¡¨ç°åˆ†æ
- **æ”¹è¿›å»ºè®®**ï¼šåŸºäºæ•°æ®çš„æ”¹è¿›å»ºè®®

### æ•™å­¦è¾…åŠ©

#### æ•™ç»ƒå‘˜æ•™å­¦å·¥å…·
- **åŠ¨ä½œæ¼”ç¤º**ï¼šæ ‡å‡†åŠ¨ä½œçš„è§†é¢‘æ¼”ç¤º
- **é”™è¯¯è¯†åˆ«**ï¼šè‡ªåŠ¨è¯†åˆ«å¸¸è§é”™è¯¯
- **æ•™å­¦è§†é¢‘åˆ¶ä½œ**ï¼šåˆ¶ä½œæ•™å­¦è§†é¢‘
- **å­¦ç”Ÿè¯„ä¼°**ï¼šè‡ªåŠ¨è¯„ä¼°å­¦ç”ŸåŠ¨ä½œ

#### å­¦å‘˜å­¦ä¹ è¾…åŠ©
- **åŠ¨ä½œå¯¹æ¯”**ï¼šå¯¹æ¯”è‡ªå·±çš„åŠ¨ä½œå’Œæ ‡å‡†åŠ¨ä½œ
- **å®æ—¶åé¦ˆ**ï¼šç»ƒä¹ æ—¶çš„å®æ—¶åé¦ˆ
- **å­¦ä¹ è¿›åº¦è·Ÿè¸ª**ï¼šè·Ÿè¸ªå­¦ä¹ è¿›åº¦
- **ä¸ªæ€§åŒ–å»ºè®®**ï¼šä¸ªæ€§åŒ–çš„å­¦ä¹ å»ºè®®

### ç§‘ç ”ç”¨é€”

#### è®¡ç®—æœºè§†è§‰ç®—æ³•ç ”ç©¶
- **ç®—æ³•éªŒè¯**ï¼šéªŒè¯æ–°ç®—æ³•çš„æœ‰æ•ˆæ€§
- **åŸºå‡†æµ‹è¯•**ï¼šæä¾›æ ‡å‡†åŸºå‡†æµ‹è¯•ç¯å¢ƒ
- **æ•°æ®é›†æ„å»º**ï¼šæ„å»ºç¾½æ¯›çƒåˆ†ææ•°æ®é›†
- **è®ºæ–‡å‘è¡¨**ï¼šæ”¯æŒå­¦æœ¯è®ºæ–‡å‘è¡¨

#### æ·±åº¦å­¦ä¹ æ¨¡å‹å¼€å‘
- **æ¨¡å‹è®­ç»ƒ**ï¼šæä¾›æ¨¡å‹è®­ç»ƒç¯å¢ƒ
- **æ¨¡å‹è¯„ä¼°**ï¼šå…¨é¢çš„æ¨¡å‹è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹ä¼˜åŒ–**ï¼šæ¨¡å‹æ€§èƒ½ä¼˜åŒ–å·¥å…·
- **æ¨¡å‹éƒ¨ç½²**ï¼šæ¨¡å‹éƒ¨ç½²å’Œæ¨ç†ä¼˜åŒ–

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### æ·±åº¦å­¦ä¹ æ¡†æ¶

#### PyTorch 2.0+
- **ç‰ˆæœ¬è¦æ±‚**: 2.0 æˆ–æ›´é«˜
- **ç”¨é€”**: æ¨¡å‹è®­ç»ƒå’Œæ¨ç†
- **ç‰¹æ€§**:
  - åŠ¨æ€è®¡ç®—å›¾
  - è‡ªåŠ¨å¾®åˆ†
  - GPU åŠ é€Ÿ
  - ä¸°å¯Œçš„æ¨¡å‹åº“

#### TorchVision
- **ç‰ˆæœ¬è¦æ±‚**: 0.15 æˆ–æ›´é«˜
- **ç”¨é€”**: è®¡ç®—æœºè§†è§‰å·¥å…·
- **ç‰¹æ€§**:
  - é¢„è®­ç»ƒæ¨¡å‹
  - å›¾åƒå˜æ¢
  - æ•°æ®åŠ è½½å™¨
  - è§†é¢‘å¤„ç†

### å§¿æ€ä¼°è®¡æ¡†æ¶

#### MMPose
- **ç‰ˆæœ¬è¦æ±‚**: 1.0 æˆ–æ›´é«˜
- **ç”¨é€”**: äººä½“å§¿æ€ä¼°è®¡
- **ç‰¹æ€§**:
  - å¤šç§é¢„è®­ç»ƒæ¨¡å‹
  - é«˜ç²¾åº¦å§¿æ€æ£€æµ‹
  - å®æ—¶æ¨ç†
  - æ˜“ç”¨çš„ API

#### MMDetection
- **ç‰ˆæœ¬è¦æ±‚**: 3.0 æˆ–æ›´é«˜
- **ç”¨é€”**: ç›®æ ‡æ£€æµ‹
- **ç‰¹æ€§**:
  - ä¸°å¯Œçš„æ£€æµ‹æ¨¡å‹
  - é«˜ç²¾åº¦æ£€æµ‹
  - æ¨¡å—åŒ–è®¾è®¡
  - æ˜“äºæ‰©å±•

### å›¾åƒå¤„ç†åº“

#### OpenCV
- **ç‰ˆæœ¬è¦æ±‚**: 4.5 æˆ–æ›´é«˜
- **ç”¨é€”**: å›¾åƒå’Œè§†é¢‘å¤„ç†
- **ç‰¹æ€§**:
  - å›¾åƒè¯»å–å’Œä¿å­˜
  - è§†é¢‘è¯»å–å’Œä¿å­˜
  - å›¾åƒå˜æ¢
  - è½®å»“æ£€æµ‹
  - ç‰¹å¾æå–

#### NumPy
- **ç‰ˆæœ¬è¦æ±‚**: 1.21 æˆ–æ›´é«˜
- **ç”¨é€”**: æ•°å€¼è®¡ç®—
- **ç‰¹æ€§**:
  - å¤šç»´æ•°ç»„
  - æ•°å­¦å‡½æ•°
  - çº¿æ€§ä»£æ•°
  - å‚…é‡Œå¶å˜æ¢

#### SciPy
- **ç‰ˆæœ¬è¦æ±‚**: 1.7 æˆ–æ›´é«˜
- **ç”¨é€”**: ç§‘å­¦è®¡ç®—
- **ç‰¹æ€§**:
  - ä¿¡å·å¤„ç†
  - ä¼˜åŒ–
  - ç»Ÿè®¡åˆ†æ
  - æ’å€¼ç®—æ³•

### GUI æ¡†æ¶

#### PySide6 (Qt6)
- **ç‰ˆæœ¬è¦æ±‚**: 6.3 æˆ–æ›´é«˜
- **ç”¨é€”**: å›¾å½¢ç”¨æˆ·ç•Œé¢
- **ç‰¹æ€§**:
  - è·¨å¹³å°æ”¯æŒ
  - ä¸°å¯Œçš„æ§ä»¶
  - ä¿¡å·æ§½æœºåˆ¶
  - æ ·å¼è¡¨æ”¯æŒ

### æ•°æ®å¤„ç†åº“

#### Pandas
- **ç‰ˆæœ¬è¦æ±‚**: 1.3 æˆ–æ›´é«˜
- **ç”¨é€”**: æ•°æ®å¤„ç†å’Œåˆ†æ
- **ç‰¹æ€§**:
  - æ•°æ®æ¡†
  - æ•°æ®è¯»å†™
  - æ•°æ®æ¸…æ´—
  - æ•°æ®åˆ†æ

#### Matplotlib
- **ç‰ˆæœ¬è¦æ±‚**: 3.5 æˆ–æ›´é«˜
- **ç”¨é€”**: æ•°æ®å¯è§†åŒ–
- **ç‰¹æ€§**:
  - å¤šç§å›¾è¡¨ç±»å‹
  - è‡ªå®šä¹‰æ ·å¼
  - äº¤äº’å¼å›¾è¡¨
  - å¯¼å‡ºåŠŸèƒ½

#### Seaborn
- **ç‰ˆæœ¬è¦æ±‚**: 0.11 æˆ–æ›´é«˜
- **ç”¨é€”**: ç»Ÿè®¡æ•°æ®å¯è§†åŒ–
- **ç‰¹æ€§**:
  - é«˜çº§å›¾è¡¨
  - ç»Ÿè®¡å›¾è¡¨
  - ç¾è§‚çš„æ ·å¼
  - ç®€å•çš„ API

### å…¶ä»–å·¥å…·

#### tqdm
- **ç‰ˆæœ¬è¦æ±‚**: 4.62 æˆ–æ›´é«˜
- **ç”¨é€”**: è¿›åº¦æ¡æ˜¾ç¤º
- **ç‰¹æ€§**:
  - ç¾è§‚çš„è¿›åº¦æ¡
  - æ—¶é—´ä¼°è®¡
  - åµŒå¥—è¿›åº¦
  - æ˜“ç”¨çš„ API

#### Pillow
- **ç‰ˆæœ¬è¦æ±‚**: 9.0 æˆ–æ›´é«˜
- **ç”¨é€”**: å›¾åƒå¤„ç†
- **ç‰¹æ€§**:
  - å›¾åƒæ‰“å¼€å’Œä¿å­˜
  - å›¾åƒå˜æ¢
  - å›¾åƒæ»¤é•œ
  - å­—ä½“å¤„ç†

---

## â“ å¸¸è§é—®é¢˜ (FAQ)

<details>
<summary><b>â“ å®‰è£…é—®é¢˜</b></summary>

### Q: MMPose å®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
**A**: MMPose çš„å®‰è£…å¯èƒ½é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š

**é—®é¢˜ 1: ä¾èµ–å†²çª**
```bash
# è§£å†³æ–¹æ¡ˆï¼šåˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
python -m venv mmpose_env
source mmpose_env/bin/activate
pip install --upgrade pip
```

**é—®é¢˜ 2: CUDA ç‰ˆæœ¬ä¸åŒ¹é…**
```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# å®‰è£…åŒ¹é…çš„ PyTorch ç‰ˆæœ¬
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

**é—®é¢˜ 3: ç¼–è¯‘é”™è¯¯**
```bash
# è§£å†³æ–¹æ¡ˆï¼šå®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install openmim
mim install mmpose
mim install mmdet
```

### Q: PySide6 å®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
**A**: PySide6 çš„å®‰è£…å¯èƒ½é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š

**é—®é¢˜ 1: ç¼ºå°‘ç³»ç»Ÿä¾èµ–**
```bash
# Windows: å®‰è£… Visual C++ Redistributable
# Ubuntu: å®‰è£… Qt ä¾èµ–
sudo apt-get install libqt6gui6 libqt6widgets6
```

**é—®é¢˜ 2: ç‰ˆæœ¬å†²çª**
```bash
# è§£å†³æ–¹æ¡ˆï¼šå¸è½½æ—§ç‰ˆæœ¬
pip uninstall pyside2 pyside5
pip install pyside6
```

### Q: GPU å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
**A**: GPU å†…å­˜ä¸è¶³æ—¶ï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š

**æ–¹æ³• 1: å‡å°è¾“å…¥å¸§æ•°**
```bash
python run_combined.py \
  --video videos/test.mp4 \
  --num_frames 1  # å‡å°åˆ° 1 å¸§
```

**æ–¹æ³• 2: ä½¿ç”¨æ›´å°çš„å§¿æ€æ¨¡å‹**
```bash
python run_combined.py \
  --video videos/test.mp4 \
  --pose_model rtmpose-t  # ä½¿ç”¨æœ€å°æ¨¡å‹
```

**æ–¹æ³• 3: å‡å°åœºåœ°æ£€æµ‹é—´éš”**
```bash
python run_combined.py \
  --video videos/test.mp4 \
  --court_detection_interval 60  # å‡å°‘æ£€æµ‹é¢‘ç‡
```

**æ–¹æ³• 4: ä½¿ç”¨ CPU æ¨¡å¼**
```bash
python run_combined.py \
  --video videos/test.mp4 \
  --device cpu  # ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰
```

**æ–¹æ³• 5: åˆ†æ‰¹å¤„ç†é•¿è§†é¢‘**
```bash
# ä½¿ç”¨è§†é¢‘åˆ†å‰²å·¥å…·å°†é•¿è§†é¢‘åˆ†å‰²ä¸ºçŸ­ç‰‡æ®µ
# ç„¶ååˆ†åˆ«å¤„ç†æ¯ä¸ªç‰‡æ®µ
```

### Q: ä¸­æ–‡æ˜¾ç¤ºå¼‚å¸¸æ€ä¹ˆåŠï¼Ÿ
**A**: ä¸­æ–‡æ˜¾ç¤ºå¼‚å¸¸é€šå¸¸ç”±ä»¥ä¸‹åŸå› å¼•èµ·ï¼š

**é—®é¢˜ 1: ç¼ºå°‘ä¸­æ–‡å­—ä½“**
```python
# è§£å†³æ–¹æ¡ˆï¼šæŒ‡å®šä¸­æ–‡å­—ä½“è·¯å¾„
font_path = r"C:\Windows\Fonts\msyh.ttc"  # Windows
font_path = "/usr/share/fonts/truetype/msyh.ttc"  # Linux
```

**é—®é¢˜ 2: ç¼–ç é—®é¢˜**
```python
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ UTF-8-BOM ç¼–ç 
df.to_csv(file_path, index=False, encoding='utf-8-sig')
```

**é—®é¢˜ 3: å­—ä½“ä¸æ”¯æŒ**
```python
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“
try:
    font = ImageFont.truetype(font_path, font_size)
except:
    font = ImageFont.load_default()
```

</details>

<details>
<summary><b>â“ ä½¿ç”¨é—®é¢˜</b></summary>

### Q: å¦‚ä½•æé«˜æ£€æµ‹ç²¾åº¦ï¼Ÿ
**A**: æé«˜æ£€æµ‹ç²¾åº¦å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢å…¥æ‰‹ï¼š

**1. è°ƒæ•´æ£€æµ‹é˜ˆå€¼**
```bash
# é™ä½é˜ˆå€¼æé«˜å¬å›ç‡
python run_combined.py --threshold 0.3

# æé«˜é˜ˆå€¼æé«˜ç²¾ç¡®ç‡
python run_combined.py --threshold 0.7
```

**2. å¢åŠ è¾“å…¥å¸§æ•°**
```bash
# å¢åŠ å¸§æ•°æé«˜ç²¾åº¦
python run_combined.py --num_frames 5
```

**3. ä½¿ç”¨æ›´å¤§çš„å§¿æ€æ¨¡å‹**
```bash
# ä½¿ç”¨å¤§æ¨¡å‹æé«˜ç²¾åº¦
python run_combined.py --pose_model rtmpose-l
```

**4. å‡å°åœºåœ°æ£€æµ‹é—´éš”**
```bash
# æ›´é¢‘ç¹çš„åœºåœ°æ£€æµ‹
python run_combined.py --court_detection_interval 15
```

**5. ç¡®ä¿è§†é¢‘è´¨é‡**
- å…‰ç…§å……è¶³
- æ— é®æŒ¡
- åˆ†è¾¨ç‡ä¸ä½äº 720p
- å¸§ç‡ä¸ä½äº 25 FPS

### Q: å¦‚ä½•å¤„ç†ä¸åŒåˆ†è¾¨ç‡çš„è§†é¢‘ï¼Ÿ
**A**: ç³»ç»Ÿä¼šè‡ªåŠ¨è°ƒæ•´ï¼Œä½†å»ºè®®ï¼š

**1. è¾“å…¥è§†é¢‘åˆ†è¾¨ç‡**
- æœ€ä½åˆ†è¾¨ç‡ï¼š720p (1280Ã—720)
- æ¨èåˆ†è¾¨ç‡ï¼š1080p (1920Ã—1080)
- æœ€é«˜åˆ†è¾¨ç‡ï¼š4K (3840Ã—2160)

**2. ä¿æŒè§†é¢‘å®½é«˜æ¯”**
- å¸¸è§å®½é«˜æ¯”ï¼š16:9, 4:3
- é¿å…æ‹‰ä¼¸å˜å½¢
- ä¿æŒåŸå§‹å®½é«˜æ¯”

**3. é¿å…è¿‡åº¦å‹ç¼©**
- ä½¿ç”¨é«˜è´¨é‡ç¼–ç 
- é¿å…ä½æ¯”ç‰¹ç‡
- ä¿æŒåŸå§‹è´¨é‡

### Q: æ”¯æŒå“ªäº›è§†é¢‘æ ¼å¼ï¼Ÿ
**A**: ç³»ç»Ÿæ”¯æŒä»¥ä¸‹è§†é¢‘æ ¼å¼ï¼š

**æ”¯æŒæ ¼å¼**ï¼š
- MP4 (H.264/H.265) - æ¨è
- AVI (XVID/FFV1)
- MOV (ProRes/H.264)
- MKV (H.264/H.265)

**æ¨èç¼–ç **ï¼š
- H.264 (AVC) - å…¼å®¹æ€§æœ€å¥½
- H.265 (HEVC) - å‹ç¼©ç‡æœ€é«˜
- ProRes - è´¨é‡æœ€é«˜

**ä¸æ¨èæ ¼å¼**ï¼š
- WMV - å…¼å®¹æ€§å·®
- FLV - å·²è¿‡æ—¶
- RMVB - å·²è¿‡æ—¶

### Q: å¦‚ä½•å¤„ç†é•¿è§†é¢‘ï¼Ÿ
**A**: é•¿è§†é¢‘å¤„ç†å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ä¼˜åŒ–ï¼š

**1. åˆ†æ‰¹å¤„ç†**
```bash
# ä½¿ç”¨è§†é¢‘åˆ†å‰²å·¥å…·
ffmpeg -i long_video.mp4 -c copy -map 0 -segment_time 300 part_%03d.mp4

# ç„¶ååˆ†åˆ«å¤„ç†æ¯ä¸ªç‰‡æ®µ
python run_combined.py --video part_001.mp4
python run_combined.py --video part_002.mp4
```

**2. è°ƒæ•´å¤„ç†å‚æ•°**
```bash
# å‡å°‘åœºåœ°æ£€æµ‹é¢‘ç‡
python run_combined.py --court_detection_interval 60

# å‡å°é¢„è§ˆæŠ½æ ·é—´éš”
python run_combined.py --emit_every 10
```

**3. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹**
```bash
# ä½¿ç”¨æ›´å°çš„å§¿æ€æ¨¡å‹
python run_combined.py --pose_model rtmpose-t

# å‡å°è¾“å…¥å¸§æ•°
python run_combined.py --num_frames 1
```

**4. ç›‘æ§èµ„æºä½¿ç”¨**
```bash
# ä½¿ç”¨ GPU ç›‘æ§å·¥å…·
nvidia-smi -l 1

# ç›‘æ§å†…å­˜ä½¿ç”¨
watch -n 1 nvidia-smi
```

</details>

<details>
<summary><b>â“ æ€§èƒ½é—®é¢˜</b></summary>

### Q: å¤„ç†é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ
**A**: å¤„ç†é€Ÿåº¦æ…¢å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ä¼˜åŒ–ï¼š

**1. ä½¿ç”¨ GPU**
```bash
# ç¡®ä¿ä½¿ç”¨ GPU
python run_combined.py --device cuda

# æ£€æŸ¥ GPU å¯ç”¨æ€§
python -c "import torch; print(torch.cuda.is_available())"
```

**2. å‡å°åœºåœ°æ£€æµ‹é—´éš”**
```bash
# å‡å°‘æ£€æµ‹é¢‘ç‡
python run_combined.py --court_detection_interval 60
```

**3. ä½¿ç”¨æ›´å°çš„å§¿æ€æ¨¡å‹**
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python run_combined.py --pose_model rtmpose-s
```

**4. å…³é—­ä¸å¿…è¦çš„å¯è§†åŒ–**
```python
# åœ¨ä»£ç ä¸­æ³¨é‡Šæ‰ä¸å¿…è¦çš„å¯è§†åŒ–
# æˆ–è€…å‡å°‘å¯è§†åŒ–æ›´æ–°é¢‘ç‡
emit_every_n_frames = 10  # ä» 1 å¢åŠ åˆ° 10
```

**5. ä¼˜åŒ–æ•°æ®åŠ è½½**
```python
# ä½¿ç”¨å¤šçº¿ç¨‹æ•°æ®åŠ è½½
from torch.utils.data import DataLoader

dataloader = DataLoader(
    dataset,
    batch_size=1,
    num_workers=4,  # å¤šçº¿ç¨‹åŠ è½½
    pin_memory=True  # é”é¡µå†…å­˜
)
```

### Q: å†…å­˜å ç”¨è¿‡é«˜æ€ä¹ˆåŠï¼Ÿ
**A**: å†…å­˜å ç”¨è¿‡é«˜å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ä¼˜åŒ–ï¼š

**1. å‡å°è¾“å…¥å¸§æ•°**
```bash
python run_combined.py --num_frames 1
```

**2. ä½¿ç”¨æ›´å°çš„å§¿æ€æ¨¡å‹**
```bash
python run_combined.py --pose_model rtmpose-t
```

**3. åˆ†æ‰¹å¤„ç†é•¿è§†é¢‘**
```bash
# å°†é•¿è§†é¢‘åˆ†å‰²ä¸ºçŸ­ç‰‡æ®µ
ffmpeg -i long_video.mp4 -c copy -map 0 -segment_time 300 part_%03d.mp4
```

**4. æ¸…ç†ç¼“å­˜**
```python
import gc
import torch

# æ¸…ç† GPU ç¼“å­˜
torch.cuda.empty_cache()

# æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
gc.collect()
```

**5. ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„**
```python
# ä½¿ç”¨ Numpy æ•°ç»„è€Œä¸æ˜¯ Python åˆ—è¡¨
import numpy as np

# å¥½çš„
data = [1, 2, 3, 4, 5]

# ä¸å¥½
data = np.array([1, 2, 3, 4, 5])
```

### Q: å¦‚ä½•ç›‘æ§æ€§èƒ½ï¼Ÿ
**A**: å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ç›‘æ§æ€§èƒ½ï¼š

**1. GPU ç›‘æ§**
```bash
# å®æ—¶ç›‘æ§
nvidia-smi -l 1

# æŒç»­ç›‘æ§
watch -n 1 nvidia-smi

# è®°å½•åˆ°æ–‡ä»¶
nvidia-smi -l 1 > gpu_usage.log
```

**2. CPU ç›‘æ§**
```bash
# Linux
htop

# Windows
taskmgr

# Python
import psutil
print(psutil.cpu_percent())
print(psutil.virtual_memory())
```

**3. å†…å­˜ç›‘æ§**
```bash
# Python
import psutil
print(psutil.virtual_memory())

# PyTorch
import torch
print(torch.cuda.memory_allocated())
print(torch.cuda.memory_reserved())
```

**4. æ€§èƒ½åˆ†æ**
```python
# ä½¿ç”¨ Python profiler
import cProfile

cProfile.run('main()', sort='cumtime')

# ä½¿ç”¨ PyTorch profiler
with torch.profiler.profile() as prof:
    model(input_data)

print(prof.key_averages())
```

</details>

<details>
<summary><b>â“ é”™è¯¯å¤„ç†</b></summary>

### Q: é‡åˆ° "CUDA out of memory" é”™è¯¯æ€ä¹ˆåŠï¼Ÿ
**A**: è¿™æ˜¯ GPU å†…å­˜ä¸è¶³çš„é”™è¯¯ï¼Œå¯ä»¥å°è¯•ï¼š

**1. æ¸…ç† GPU ç¼“å­˜**
```python
import torch
torch.cuda.empty_cache()
```

**2. å‡å°æ‰¹æ¬¡å¤§å°**
```python
batch_size = 1  # ä»æ›´å¤§çš„å€¼å‡å°åˆ° 1
```

**3. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯**
```python
accumulation_steps = 4
for i, batch in enumerate(dataloader):
    outputs = model(batch)
    loss = criterion(outputs, targets)
    loss = loss / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**4. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = model(inputs)
    loss = criterion(outputs, targets)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### Q: é‡åˆ° "Model not found" é”™è¯¯æ€ä¹ˆåŠï¼Ÿ
**A**: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯ä»¥å°è¯•ï¼š

**1. æ£€æŸ¥æ¨¡å‹è·¯å¾„**
```bash
# ç¡®è®¤æ¨¡å‹æ–‡ä»¶å­˜åœ¨
ls -la models/

# æ£€æŸ¥æ–‡ä»¶æƒé™
chmod 644 models/*.pt
chmod 644 models/*.pth
```

**2. ä¸‹è½½æ¨¡å‹**
```bash
# è¿è¡Œä¸‹è½½è„šæœ¬
python scripts/download_models.py
```

**3. æ£€æŸ¥æ¨¡å‹æ ¼å¼**
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ ¼å¼
file models/ball_track_attention.pt
file models/court_kpRCNN.pth
```

### Q: é‡åˆ° "Video cannot be opened" é”™è¯¯æ€ä¹ˆåŠï¼Ÿ
**A**: è§†é¢‘æ–‡ä»¶æ— æ³•æ‰“å¼€ï¼Œå¯ä»¥å°è¯•ï¼š

**1. æ£€æŸ¥è§†é¢‘è·¯å¾„**
```bash
# ç¡®è®¤è§†é¢‘æ–‡ä»¶å­˜åœ¨
ls -la videos/

# æ£€æŸ¥æ–‡ä»¶æƒé™
chmod 644 videos/*.mp4
```

**2. æ£€æŸ¥è§†é¢‘æ ¼å¼**
```bash
# ä½¿ç”¨ ffprobe æ£€æŸ¥è§†é¢‘ä¿¡æ¯
ffprobe -v videos/test.mp4
```

**3. è½¬æ¢è§†é¢‘æ ¼å¼**
```bash
# è½¬æ¢ä¸º MP4 æ ¼å¼
ffmpeg -i input.avi -c:v libx264 -c:a aac output.mp4
```

**4. æ£€æŸ¥ç¼–è§£ç å™¨**
```bash
# å®‰è£…å¿…è¦çš„ç¼–è§£ç å™¨
sudo apt-get install libx264-dev
sudo apt-get install libfaac-dev
```

</details>

---

## ğŸ”§ æ‰©å±•å’Œå®šåˆ¶æŒ‡å—

### æ‰©å±•æ€§æ¶æ„å›¾

```mermaid
graph TB
    A[æ ¸å¿ƒç³»ç»Ÿ] --> B[æ£€æµ‹æ¨¡å—]
    A --> C[åˆ†ç±»æ¨¡å—]
    A --> D[å¯è§†åŒ–æ¨¡å—]
    
    B --> E[çƒä½“æ£€æµ‹]
    B --> F[å§¿æ€æ£€æµ‹]
    B --> G[äº‹ä»¶æ£€æµ‹]
    
    C --> H[å‡»çƒåˆ†ç±»]
    C --> I[æ–°åˆ†ç±»å™¨]
    C --> J[è‡ªå®šä¹‰åˆ†ç±»å™¨]
    
    D --> K[é»˜è®¤å¯è§†åŒ–]
    D --> L[è‡ªå®šä¹‰å¯è§†åŒ–]
    D --> M[ç¬¬ä¸‰æ–¹å¯è§†åŒ–]
    
    E --> N[æ’ä»¶æ¥å£]
    F --> N
    G --> N
    H --> N
    I --> N
    J --> N
    K --> N
    L --> N
    M --> N
    
    N --> O[æ‰©å±•ç‚¹ 1: æ–°æ¨¡å‹]
    N --> P[æ‰©å±•ç‚¹ 2: æ–°ç®—æ³•]
    N --> Q[æ‰©å±•ç‚¹ 3: æ–°å¯è§†åŒ–]
    N --> R[æ‰©å±•ç‚¹ 4: æ–°æŒ‡æ ‡]
    
    O --> S[æ³¨å†Œæœºåˆ¶]
    P --> S
    Q --> S
    R --> S
    
    S --> T[åŠ¨æ€åŠ è½½]
    T --> U[é…ç½®ç®¡ç†]
    U --> V[ç‰ˆæœ¬å…¼å®¹]
```

### æ·»åŠ æ–°çš„å‡»çƒç±»å‹

#### æ­¥éª¤ 1: å®šä¹‰æ–°ç±»å‹
```python
# core/stroke_types.py
NEW_STROKE_TYPES = [
    {
        "id": 36,
        "name": "æ­£æ‰‹è·³æ€",
        "name_en": "forehand_jump_smash"
    },
    {
        "id": 37,
        "name": "åæ‰‹è·³æ€",
        "name_en": "backhand_jump_smash"
    }
]
```

#### æ­¥éª¤ 2: ä¿®æ”¹æ¨¡å‹
```python
# core/bst.py
class BST_Extended(nn.Module):
    def __init__(self, in_dim, seq_len, n_class=37, ...):
        # å¢åŠ ç±»åˆ«æ•°
        super().__init__()
        # ... å…¶ä»–ä»£ç 
```

#### æ­¥éª¤ 3: é‡æ–°è®­ç»ƒ
```bash
# å‡†å¤‡æ•°æ®
python scripts/prepare_extended_data.py \
  --input_dir data/raw \
  --output_dir data/extended

# è®­ç»ƒæ¨¡å‹
python scripts/train_bst.py \
  --model_type BST_Extended \
  --data_dir data/extended \
  --n_classes 37 \
  --epochs 100 \
  --batch_size 32 \
  --lr 0.001

# è¯„ä¼°æ¨¡å‹
python scripts/evaluate_bst.py \
  --model_path models/bst_extended.pth \
  --test_dir data/extended/test
```

### é›†æˆæ–°çš„å§¿æ€æ¨¡å‹

#### æ­¥éª¤ 1: å‡†å¤‡æ¨¡å‹
```python
# core/pose_detectors.py
from mmpose.apis import init_model

class CustomPoseDetector:
    def __init__(self, config_path, checkpoint_path, device='cuda'):
        self.model = init_model(config_path, checkpoint_path, device=device)
        self.device = device
    
    def detect(self, image):
        # è‡ªå®šä¹‰æ£€æµ‹é€»è¾‘
        results = inference_top_down_pose_model(
            self.model,
            image,
            person_results=person_results,
            bbox_thr=0.3
        )
        return results
```

#### æ­¥éª¤ 2: é›†æˆåˆ°æµæ°´çº¿
```python
# run_combined.py
from core.pose_detectors import CustomPoseDetector

detector = CustomPoseDetector(
    config_path='configs/custom_pose.py',
    checkpoint_path='models/custom_pose.pth',
    device='cuda'
)

poses, video_info = detector.detect_video(video_path)
```

### è‡ªå®šä¹‰å¯è§†åŒ–

#### æ­¥éª¤ 1: åˆ›å»ºå¯è§†åŒ–ç±»
```python
# core/visualizers.py
import cv2
import numpy as np

class CustomVisualizer:
    def __init__(self, output_path):
        self.output_path = output_path
        self.writer = cv2.VideoWriter(
            output_path,
            cv2.VideoWriter_fourcc(*'mp4v'),
            30,
            (1920, 1080)
        )
    
    def add_frame(self, frame, ball_pos, poses, hits):
        # è‡ªå®šä¹‰å¯è§†åŒ–é€»è¾‘
        vis_frame = frame.copy()
        
        # ç»˜åˆ¶çƒä½“
        if ball_pos is not None:
            cv2.circle(vis_frame, ball_pos, 10, (0, 255, 0), -1)
        
        # ç»˜åˆ¶å§¿æ€
        if poses is not None:
            vis_frame = self._draw_poses(vis_frame, poses)
        
        # ç»˜åˆ¶å‡»çƒç‚¹
        for hit in hits:
            cv2.circle(vis_frame, hit, 15, (255, 0, 0), 2)
        
        self.writer.write(vis_frame)
    
    def _draw_poses(self, frame, poses):
        # ç»˜åˆ¶å§¿æ€
        return frame
    
    def release(self):
        self.writer.release()
```

#### æ­¥éª¤ 2: ä½¿ç”¨è‡ªå®šä¹‰å¯è§†åŒ–
```python
# run_combined.py
from core.visualizers import CustomVisualizer

visualizer = CustomVisualizer('output_custom.mp4')

for frame_idx, frame in enumerate(video):
    ball_pos = trajectory_data[frame_idx]
    poses = poses_data[frame_idx]
    hits = [trajectory_data[h] for h in hit_frames if h == frame_idx]
    
    visualizer.add_frame(frame, ball_pos, poses, hits)

visualizer.release()
```

### æ·»åŠ æ–°çš„åˆ†ææŒ‡æ ‡

#### æ­¥éª¤ 1: å®šä¹‰æŒ‡æ ‡
```python
# core/metrics.py
def calculate_stroke_diversity(stroke_types):
    """
    è®¡ç®—å‡»çƒå¤šæ ·æ€§
    """
    from collections import Counter
    counter = Counter(stroke_types)
    diversity = len(counter) / len(stroke_types)
    return diversity

def calculate_rally_length(hit_frames):
    """
    è®¡ç®—å›åˆé•¿åº¦
    """
    rally_lengths = []
    for i in range(1, len(hit_frames)):
        rally_lengths.append(hit_frames[i] - hit_frames[i-1])
    return np.mean(rally_lengths)

def calculate_aggressiveness(stroke_types):
    """
    è®¡ç®—è¿›æ”»æ€§
    """
    aggressive_strokes = [2, 16, 17, 20, 33, 34, 35]  # æ€çƒ ID
    aggressive_count = sum(1 for s in stroke_types if s in aggressive_strokes)
    return aggressive_count / len(stroke_types)
```

#### æ­¥éª¤ 2: é›†æˆåˆ°åˆ†æ
```python
# scripts/analyze_performance.py
from core.metrics import (
    calculate_stroke_diversity,
    calculate_rally_length,
    calculate_aggressiveness
)

def analyze_performance(stroke_types, hit_frames):
    diversity = calculate_stroke_diversity(stroke_types)
    rally_length = calculate_rally_length(hit_frames)
    aggressiveness = calculate_aggressiveness(stroke_types)
    
    return {
        'diversity': diversity,
        'rally_length': rally_length,
        'aggressiveness': aggressiveness
    }
```

### éƒ¨ç½²åˆ°äº‘ç«¯

#### æ­¥éª¤ 1: å®¹å™¨åŒ–
```dockerfile
# Dockerfile
FROM pytorch/pytorch:2.0.0-cuda11.8-cudnn8-runtime

RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender1 \
    libxrandr2

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . /app
WORKDIR /app

CMD ["python", "run_combined.py"]
```

#### æ­¥éª¤ 2: æ„å»ºé•œåƒ
```bash
docker build -t tracknetv3-attention:latest .
```

#### æ­¥éª¤ 3: è¿è¡Œå®¹å™¨
```bash
docker run --gpus all \
  -v $(pwd)/videos:/app/videos \
  -v $(pwd)/results:/app/results \
  tracknetv3-attention:latest \
  python run_combined.py \
    --video /app/videos/test.mp4 \
    --result_dir /app/results
```

### é›†æˆåˆ° Web åº”ç”¨

#### æ­¥éª¤ 1: åˆ›å»º API
```python
# api/app.py
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
import uvicorn

app = FastAPI()

@app.post("/analyze")
async def analyze_video(file: UploadFile = File(...)):
    # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘
    video_path = f"uploads/{file.filename}"
    with open(video_path, "wb") as buffer:
        buffer.write(await file.read())
    
    # è¿è¡Œåˆ†æ
    result_dir = f"results/{file.filename}"
    run_combined_pipeline(video_path, result_dir)
    
    # è¿”å›ç»“æœ
    return {
        "status": "success",
        "result_dir": result_dir
    }

@app.get("/download/{filename}")
async def download_result(filename: str):
    file_path = f"results/{filename}"
    return FileResponse(file_path)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### æ­¥éª¤ 2: éƒ¨ç½²
```bash
# å®‰è£…ä¾èµ–
pip install fastapi uvicorn python-multipart

# è¿è¡Œ API
python api/app.py

# è®¿é—® API
curl -X POST "http://localhost:8000/analyze" \
  -F "file=@test.mp4"
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ
- **CPU**: Intel Core i9-11900K @ 3.50GHz
- **GPU**: NVIDIA RTX 3090 24GB
- **å†…å­˜**: 64GB DDR4 3200MHz
- **å­˜å‚¨**: 1TB NVMe SSD
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 22.04 LTS
- **CUDA**: 11.8
- **PyTorch**: 2.0.1
- **Python**: 3.9.16

### æµ‹è¯•æ•°æ®é›†

#### æ•°æ®æµå‘å›¾

```mermaid
graph LR
    A[åŸå§‹è§†é¢‘] --> B[é¢„å¤„ç†]
    B --> C[çƒä½“æ£€æµ‹]
    B --> D[å§¿æ€æ£€æµ‹]
    B --> E[åœºåœ°æ£€æµ‹]
    
    C --> F[è½¨è¿¹æ•°æ®]
    D --> G[å§¿æ€æ•°æ®]
    E --> H[åœºåœ°æ•°æ®]
    
    F --> I[äº‹ä»¶æ£€æµ‹]
    G --> I
    H --> I
    
    I --> J[å‡»çƒåˆ†ç±»]
    J --> K[åˆ†ç±»ç»“æœ]
    
    F --> L[è½¨è¿¹å¹³æ»‘]
    L --> M[å¹³æ»‘è½¨è¿¹]
    
    M --> N[å¯è§†åŒ–åˆæˆ]
    G --> N
    H --> N
    K --> N
    
    N --> O[è¾“å‡ºè§†é¢‘]
    N --> P[è¾“å‡º CSV]
    N --> Q[è¾“å‡º JSON]
```

| æ•°æ®é›† | è§†é¢‘æ•° | æ€»æ—¶é•¿ | åˆ†è¾¨ç‡ | å¸§ç‡ |
|--------|--------|--------|--------|------|
| Test Set A | 10 | 50 åˆ†é’Ÿ | 1080p | 60 FPS |
| Test Set B | 10 | 50 åˆ†é’Ÿ | 720p | 30 FPS |
| Test Set C | 10 | 50 åˆ†é’Ÿ | 4K | 30 FPS |
| **æ€»è®¡** | **30** | **150 åˆ†é’Ÿ** | - | - |

### æ£€æµ‹æ€§èƒ½åŸºå‡†

#### çƒä½“æ£€æµ‹
| æ¨¡å‹ | è¾“å…¥å¸§æ•° | é˜ˆå€¼ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1 | FPS | GPU å†…å­˜ |
|------|----------|--------|--------|--------|-----|-----|----------|
| TrackNetV3 | 3 | 0.5 | 93.5% | 91.2% | 92.3% | 145 | 1.8 GB |
| TrackNetV3 | 5 | 0.5 | 95.2% | 93.8% | 94.5% | 98 | 2.1 GB |
| TrackNetV3+CBAM | 3 | 0.5 | 94.8% | 92.5% | 93.6% | 132 | 2.0 GB |
| TrackNetV3+CBAM | 5 | 0.5 | 96.3% | 94.7% | 95.5% | 89 | 2.3 GB |

#### å§¿æ€æ£€æµ‹
| æ¨¡å‹ | è¾“å…¥åˆ†è¾¨ç‡ | COCO mAP | AR@10 | AR@20 | FPS | GPU å†…å­˜ |
|------|------------|-----------|-------|-------|-----|----------|
| RTMPose-T | 256Ã—192 | 0.72 | 0.80 | 0.88 | 78 | 2.8 GB |
| RTMPose-S | 256Ã—192 | 0.75 | 0.82 | 0.90 | 65 | 3.2 GB |
| RTMPose-M | 256Ã—192 | 0.78 | 0.85 | 0.92 | 45 | 3.5 GB |
| RTMPose-L | 256Ã—192 | 0.80 | 0.87 | 0.94 | 28 | 4.8 GB |

#### åœºåœ°æ£€æµ‹
| æ¨¡å‹ | å…³é”®ç‚¹å‡†ç¡®ç‡ | è¾¹ç•Œè¯¯å·® | FPS | GPU å†…å­˜ |
|------|--------------|----------|-----|----------|
| Keypoint RCNN | 96.5% | 2.3 åƒç´  | 30 | 1.8 GB |

#### å‡»çƒäº‹ä»¶æ£€æµ‹
| é…ç½® | å¬å›ç‡ | ç²¾ç¡®ç‡ | F1 | è¯¯æ£€ç‡ | æ¼æ£€ç‡ |
|------|--------|--------|-----|--------|--------|
| é«˜å¬å›ç‡ | 95.2% | 85.3% | 90.0% | 14.7% | 4.8% |
| å¹³è¡¡é…ç½® | 91.2% | 88.5% | 89.8% | 11.5% | 8.8% |
| é«˜ç²¾ç¡®ç‡ | 87.5% | 92.3% | 89.8% | 7.7% | 12.5% |

#### å‡»çƒç±»å‹åˆ†ç±»
| æ¨¡å‹ | æ•°æ®é›† | å‡†ç¡®ç‡ | Top-3 | Top-5 | FPS | GPU å†…å­˜ |
|------|--------|--------|-------|-------|-----|----------|
| BST | Shuttleset | 83.5% | 92.8% | 96.2% | 95 | 4.0 GB |
| BST_CG | Shuttleset | 85.2% | 93.5% | 96.8% | 88 | 4.1 GB |
| BST_AP | Shuttleset | 84.8% | 93.2% | 96.5% | 90 | 4.1 GB |
| BST_CG_AP | Shuttleset | 86.3% | 94.7% | 97.2% | 80 | 4.2 GB |

### ç³»ç»Ÿæ€§èƒ½åŸºå‡†

#### å¤„ç†é€Ÿåº¦
| è§†é¢‘é•¿åº¦ | åˆ†è¾¨ç‡ | å¸§ç‡ | å¤„ç†æ—¶é—´ | å¹³å‡é€Ÿåº¦ | å®æ—¶å€æ•° |
|----------|--------|------|----------|----------|----------|
| 1 åˆ†é’Ÿ | 1080p | 60 | 2.5 åˆ†é’Ÿ | 24 FPS | 0.40Ã— |
| 5 åˆ†é’Ÿ | 1080p | 60 | 11.8 åˆ†é’Ÿ | 25 FPS | 0.42Ã— |
| 10 åˆ†é’Ÿ | 1080p | 60 | 23.5 åˆ†é’Ÿ | 26 FPS | 0.43Ã— |
| 30 åˆ†é’Ÿ | 1080p | 60 | 68.2 åˆ†é’Ÿ | 24 FPS | 0.40Ã— |

#### èµ„æºå ç”¨
| ç»„ä»¶ | CPU | GPU | å†…å­˜ |
|------|-----|-----|------|
| çƒä½“æ£€æµ‹ | 15% | 25% | 2.1 GB |
| å§¿æ€æ£€æµ‹ | 25% | 35% | 3.5 GB |
| åœºåœ°æ£€æµ‹ | 10% | 15% | 1.8 GB |
| äº‹ä»¶æ£€æµ‹ | 5% | 5% | 0.5 GB |
| å‡»çƒåˆ†ç±» | 8% | 20% | 4.2 GB |
| å¯è§†åŒ– | 20% | 30% | 2.8 GB |
| **æ€»è®¡** | **83%** | **130%** | **14.9 GB** |

### å¯¹æ¯”åˆ†æ

#### ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | çƒä½“æ£€æµ‹ F1 | å§¿æ€æ£€æµ‹ mAP | å‡»çƒæ£€æµ‹ F1 | å‡»çƒåˆ†ç±»å‡†ç¡®ç‡ |
|------|-------------|--------------|-------------|----------------|
| TrackNetV3 | 92.3% | - | - | - |
| TrackNetV3+CBAM | 95.5% | - | - | - |
| æœ¬é¡¹ç›® | 95.5% | 0.78 | 89.8% | 86.3% |

#### ä¼˜åŠ¿åˆ†æ
âœ… **æ›´é«˜çš„æ£€æµ‹ç²¾åº¦**: CBAM æ³¨æ„åŠ›æœºåˆ¶æå‡ 3.2% F1
âœ… **æ›´å®Œæ•´çš„ç³»ç»Ÿ**: é›†æˆæ£€æµ‹ã€è·Ÿè¸ªã€åˆ†ç±»ã€å¯è§†åŒ–
âœ… **æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ**: PySide6 å›¾å½¢ç•Œé¢ï¼Œæ˜“äºä½¿ç”¨
âœ… **æ›´ä¸°å¯Œçš„åŠŸèƒ½**: å‡»çƒç±»å‹åˆ†ç±»ã€äº‹ä»¶æ£€æµ‹ã€è½¨è¿¹å¹³æ»‘
âœ… **æ›´å¥½çš„æ‰©å±•æ€§**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºå®šåˆ¶å’Œæ‰©å±•

---

## ğŸ”§ æ•…éšœæ’é™¤å®Œæ•´æŒ‡å—

### æ•…éšœæ’é™¤æµç¨‹å›¾

```mermaid
graph TB
    A[é‡åˆ°é—®é¢˜] --> B{é—®é¢˜ç±»å‹}
    
    B -->|å†…å­˜ä¸è¶³| C[æ¸…ç† GPU ç¼“å­˜]
    B -->|æ¨¡å‹æœªæ‰¾åˆ°| D[æ£€æŸ¥æ¨¡å‹æ–‡ä»¶]
    B -->|è§†é¢‘æ— æ³•æ‰“å¼€| E[æ£€æŸ¥è§†é¢‘æ ¼å¼]
    B -->|æ£€æµ‹å¤±è´¥| F[æ£€æŸ¥è¾“å…¥æ•°æ®]
    B -->|æ€§èƒ½ç“¶é¢ˆ| G[ä½¿ç”¨ profiler]
    
    C --> H[å‡å°æ‰¹æ¬¡å¤§å°]
    D --> I[ä¸‹è½½æ¨¡å‹]
    E --> J[è½¬æ¢è§†é¢‘æ ¼å¼]
    F --> K[å¯è§†åŒ–è°ƒè¯•]
    G --> L[åˆ†ææ€§èƒ½]
    
    H --> M[é—®é¢˜è§£å†³]
    I --> M
    J --> M
    K --> M
    L --> M
```

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### é”™è¯¯ 1: CUDA out of memory
```
RuntimeError: CUDA out of memory. Tried to allocate 2.34 GiB
```

**åŸå› **: GPU æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ³• 1: æ¸…ç†ç¼“å­˜
import torch
torch.cuda.empty_cache()

# æ–¹æ³• 2: å‡å°æ‰¹æ¬¡å¤§å°
batch_size = 1  # ä»æ›´å¤§çš„å€¼å‡å°

# æ–¹æ³• 3: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4
for i, batch in enumerate(dataloader):
    outputs = model(batch)
    loss = criterion(outputs, targets)
    loss = loss / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()

# æ–¹æ³• 4: ä½¿ç”¨æ··åˆç²¾åº¦
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = model(inputs)
    loss = criterion(outputs, targets)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

#### é”™è¯¯ 2: Model not found
```
FileNotFoundError: [Errno 2] No such file or directory: 'models/ball_track_attention.pt'
```

**åŸå› **: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -la models/

# ä¸‹è½½æ¨¡å‹
python scripts/download_models.py

# æ£€æŸ¥æ–‡ä»¶æƒé™
chmod 644 models/*.pt models/*.pth

# éªŒè¯æ¨¡å‹æ ¼å¼
python -c "
import torch
model = torch.load('models/ball_track_attention.pt', map_location='cpu')
print(model.keys())
"
```

#### é”™è¯¯ 3: Video cannot be opened
```
cv2.error: OpenCV(4.5.0) error: (-5:Bad argument) 
in function 'VideoCapture'
```

**åŸå› **: è§†é¢‘æ–‡ä»¶æŸåæˆ–æ ¼å¼ä¸æ”¯æŒ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥è§†é¢‘æ–‡ä»¶
ls -la videos/test.mp4

# ä½¿ç”¨ ffprobe æ£€æŸ¥
ffprobe -v error videos/test.mp4

# è½¬æ¢è§†é¢‘æ ¼å¼
ffmpeg -i input.avi -c:v libx264 -c:a aac output.mp4

# é‡æ–°ç¼–ç 
ffmpeg -i input.mp4 -c:v libx264 -preset slow -crf 18 output.mp4
```

#### é”™è¯¯ 4: No valid trajectory points found
```
ValueError: No valid trajectory points found!
```

**åŸå› **: è½¨è¿¹æ•°æ®ä¸ºç©ºæˆ–æ— æ•ˆ

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥è½¨è¿¹æ•°æ®
import json
with open('loca_info/test.json', 'r') as f:
    trajectory = json.load(f)

print(f"è½¨è¿¹ç‚¹æ•°: {len(trajectory)}")
print(f"æœ‰æ•ˆè½¨è¿¹ç‚¹æ•°: {sum(1 for p in trajectory if p is not None)}")
print(f"æ— æ•ˆè½¨è¿¹ç‚¹æ•°: {sum(1 for p in trajectory if p is None)}")

# å¯è§†åŒ–è½¨è¿¹
import matplotlib.pyplot as plt
x = [p[0] for p in trajectory if p is not None]
y = [p[1] for p in trajectory if p is not None]
plt.scatter(x, y, alpha=0.5)
plt.title('çƒä½“è½¨è¿¹')
plt.xlabel('X åæ ‡')
plt.ylabel('Y åæ ‡')
plt.grid(True)
plt.show()
```

#### é”™è¯¯ 5: Pose detection failed
```
RuntimeError: MMPose inference failed
```

**åŸå› **: MMPose æ¨¡å‹åŠ è½½æˆ–æ¨ç†å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥ MMPose å®‰è£…
import mmpose
print(mmpose.__version__)

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
from mmpose.apis import init_model
config_file = 'configs/rtmpose/rtmpose-m_256x192.py'
checkpoint_file = 'models/rtmpose-m.pth'

model = init_model(config_file, checkpoint_file, device='cpu')
print(model)

# æµ‹è¯•æ¨ç†
from mmpose.apis import inference_top_down_pose_model
results = inference_top_down_pose_model(
    model,
    image,
    person_results=person_results,
    bbox_thr=0.3
)
print(results)
```

### æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### GPU ä¼˜åŒ–
```python
# ä½¿ç”¨ torch.backends.cudnn.benchmark
import torch
torch.backends.cudnn.benchmark = True

# ä½¿ç”¨éé˜»å¡å¼‚æ­¥ä¼ è¾“
stream = torch.cuda.Stream()
with torch.cuda.stream(stream):
    output = model(input)

# ä½¿ç”¨ pin_memory
dataloader = DataLoader(dataset, batch_size=32, 
                       pin_memory=True, num_workers=4)
```

#### CPU ä¼˜åŒ–
```python
# ä½¿ç”¨å¤šè¿›ç¨‹
from multiprocessing import Pool

def process_video(video_path):
    # å¤„ç†è§†é¢‘
    pass

with Pool(processes=4) as pool:
    results = pool.map(process_video, video_paths)

# ä½¿ç”¨ numba åŠ é€Ÿ
from numba import jit

@jit(nopython=True)
def calculate_angle(vec1, vec2):
    # è®¡ç®—è§’åº¦
    pass
```

#### å†…å­˜ä¼˜åŒ–
```python
# ä½¿ç”¨ç”Ÿæˆå™¨
def read_trajectory(file_path):
    with open(file_path, 'r') as f:
        for line in f:
            yield json.loads(line)

# ä½¿ç”¨å†…å­˜æ˜ å°„
import numpy as np
data = np.memmap('large_array.npy', dtype='float32', mode='r')

# ä½¿ç”¨ del åŠæ—¶é‡Šæ”¾å†…å­˜
large_data = load_large_data()
process(large_data)
del large_data
import gc
gc.collect()
```

### è°ƒè¯•æŠ€å·§

#### è°ƒè¯•æµç¨‹å›¾

```mermaid
graph TB
    A[å¼€å§‹è°ƒè¯•] --> B{è°ƒè¯•æ–¹æ³•}
    
    B -->|æ—¥å¿—è®°å½•| C[è®¾ç½®æ—¥å¿—çº§åˆ«]
    B -->|å¯è§†åŒ–è°ƒè¯•| D[ç”Ÿæˆè°ƒè¯•å›¾è¡¨]
    B -->|æ–­ç‚¹è°ƒè¯•| E[è®¾ç½®æ–­ç‚¹]
    B -->|æ€§èƒ½åˆ†æ| F[ä½¿ç”¨ profiler]
    
    C --> G[è®°å½•å…³é”®ä¿¡æ¯]
    G --> H[ä¿å­˜æ—¥å¿—æ–‡ä»¶]
    H --> I[åˆ†ææ—¥å¿—]
    
    D --> J[ç”Ÿæˆè½¨è¿¹å›¾]
    D --> K[ç”Ÿæˆæ—¶é—´åºåˆ—å›¾]
    D --> L[ç”Ÿæˆé€Ÿåº¦æ›²çº¿å›¾]
    J --> M[ä¿å­˜å›¾è¡¨]
    K --> M
    L --> M
    
    E --> N[è®¾ç½®æ–­ç‚¹ä½ç½®]
    N --> O[è¿è¡Œè°ƒè¯•å™¨]
    O --> P[æ£€æŸ¥å˜é‡å€¼]
    P --> Q[å•æ­¥æ‰§è¡Œ]
    
    F --> R[å¯åŠ¨ profiler]
    R --> S[è¿è¡Œä»£ç ]
    S --> T[åˆ†ææ€§èƒ½æŠ¥å‘Š]
    T --> U[è¯†åˆ«ç“¶é¢ˆ]
    
    I --> V[é—®é¢˜å®šä½]
    M --> V
    Q --> V
    U --> V
    
    V --> W[ä¿®å¤é—®é¢˜]
    W --> X[éªŒè¯ä¿®å¤]
    X --> Y[è°ƒè¯•å®Œæˆ]
```

#### æ—¥å¿—è®°å½•
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
logger.info('å¼€å§‹å¤„ç†è§†é¢‘')
logger.debug(f'è½¨è¿¹æ•°æ®: {trajectory_data}')
logger.warning('æ£€æµ‹åˆ°å¼‚å¸¸ç‚¹')
logger.error('å¤„ç†å¤±è´¥', exc_info=True)
```

#### å¯è§†åŒ–è°ƒè¯•
```python
import matplotlib.pyplot as plt

def debug_trajectory(trajectory, hits):
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # è½¨è¿¹å›¾
    axes[0, 0].plot([p[0] for p in trajectory if p],
                      [p[1] for p in trajectory if p], 'b-')
    axes[0, 0].scatter([p[0] for p in trajectory if p],
                        [p[1] for p in trajectory if p], c='r', s=10)
    axes[0, 0].set_title('çƒä½“è½¨è¿¹')
    axes[0, 0].grid(True)
    
    # Y åæ ‡æ—¶é—´åºåˆ—
    axes[0, 1].plot([p[1] for p in trajectory if p])
    axes[0, 1].set_title('Y åæ ‡æ—¶é—´åºåˆ—')
    axes[0, 1].grid(True)
    
    # å‡»çƒç‚¹
    axes[1, 0].scatter([trajectory[h][0] for h in hits],
                        [trajectory[h][1] for h in hits], c='g', s=50)
    axes[1, 0].set_title('å‡»çƒç‚¹')
    axes[1, 0].grid(True)
    
    # é€Ÿåº¦æ›²çº¿
    velocities = [calculate_velocity(trajectory, i) 
                 for i in range(len(trajectory))]
    axes[1, 1].plot(velocities)
    axes[1, 1].set_title('é€Ÿåº¦æ›²çº¿')
    axes[1, 1].grid(True)
    
    plt.tight_layout()
    plt.savefig('debug.png', dpi=300)
    plt.show()
```

#### æ–­ç‚¹è°ƒè¯•
```python
import pdb

def process_trajectory(trajectory):
    # è®¾ç½®æ–­ç‚¹
    pdb.set_trace()
    
    # è°ƒè¯•ä»£ç 
    processed = []
    for point in trajectory:
        if point is not None:
            processed.append(point)
    
    return processed
```

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼æ— è®ºæ˜¯ä»£ç ã€æ–‡æ¡£ã€é”™è¯¯æŠ¥å‘Šè¿˜æ˜¯åŠŸèƒ½å»ºè®®ï¼Œæˆ‘ä»¬éƒ½éå¸¸æ„Ÿè°¢ã€‚

### å¦‚ä½•è´¡çŒ®

#### æŠ¥å‘Š Bug
1. åœ¨ [Issues](https://github.com/yourusername/TrackNetV3_Attention/issues) ä¸­æœç´¢æ˜¯å¦å·²æœ‰ç›¸åŒé—®é¢˜
2. å¦‚æœæ²¡æœ‰ï¼Œåˆ›å»ºæ–°çš„ Issue
3. ä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜æè¿°é—®é¢˜
4. æä¾›è¯¦ç»†çš„é‡ç°æ­¥éª¤
5. åŒ…å«ç¯å¢ƒä¿¡æ¯ï¼ˆOSã€Python ç‰ˆæœ¬ã€PyTorch ç‰ˆæœ¬ç­‰ï¼‰
6. æ·»åŠ ç›¸å…³çš„æ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯

#### æå‡ºæ–°åŠŸèƒ½
1. åœ¨ [Issues](https://github.com/yourusername/TrackNetV3_Attention/issues) ä¸­åˆ›å»ºæ–°çš„ Issue
2. æ¸…æ™°æè¿°æ–°åŠŸèƒ½
3. è¯´æ˜åŠŸèƒ½çš„ä½¿ç”¨åœºæ™¯
4. æä¾›è®¾è®¡æ€è·¯æˆ–ä¼ªä»£ç 
5. è®¨è®ºå®ç°æ–¹æ¡ˆ

#### æäº¤ä»£ç 
1. Fork é¡¹ç›®åˆ°ä½ çš„ GitHub è´¦æˆ·
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ï¼š`git checkout -b feature/your-feature-name`
3. è¿›è¡Œä¿®æ”¹å¹¶æ·»åŠ æµ‹è¯•
4. ç¡®ä¿ä»£ç é€šè¿‡æ‰€æœ‰æµ‹è¯•ï¼š`pytest`
5. æäº¤ä¿®æ”¹ï¼š`git commit -m "Add some feature"`
6. æ¨é€åˆ°åˆ†æ”¯ï¼š`git push origin feature/your-feature-name`
7. åˆ›å»º Pull Request

### ä»£ç è§„èŒƒ

#### Python ä»£ç é£æ ¼
- éµå¾ª [PEP 8](https://www.python.org/dev/peps/pep-0008/) ä»£ç é£æ ¼
- ä½¿ç”¨ 4 ç©ºæ ¼ç¼©è¿›
- æ¯è¡Œä¸è¶…è¿‡ 100 å­—ç¬¦
- ä½¿ç”¨æœ‰æ„ä¹‰çš„å˜é‡åå’Œå‡½æ•°å
- æ·»åŠ ç±»å‹æ³¨è§£
- ç¼–å†™æ–‡æ¡£å­—ç¬¦ä¸²

#### æ–‡æ¡£å­—ç¬¦ä¸²è§„èŒƒ
```python
def example_function(param1, param2):
    """
    å‡½æ•°çš„ç®€çŸ­æè¿°ã€‚
    
    è¯¦ç»†æè¿°å¯ä»¥è·¨è¶Šå¤šè¡Œã€‚
    
    Args:
        param1 (int): å‚æ•° 1 çš„æè¿°
        param2 (str): å‚æ•° 2 çš„æè¿°
    
    Returns:
        bool: è¿”å›å€¼çš„æè¿°
    
    Raises:
        ValueError: å½“å‚æ•°æ— æ•ˆæ—¶æŠ›å‡º
    
    Examples:
        >>> example_function(1, "test")
        True
    """
    pass
```

#### ç±»å‹æ³¨è§£
```python
from typing import List, Tuple, Optional, Dict

def process_data(
    data: List[float],
    threshold: float,
    options: Optional[Dict[str, any]] = None
) -> Tuple[List[float], int]:
    """
    å¤„ç†æ•°æ®å¹¶è¿”å›ç»“æœã€‚
    
    Args:
        data: è¾“å…¥æ•°æ®åˆ—è¡¨
        threshold: å¤„ç†é˜ˆå€¼
        options: å¯é€‰çš„é…ç½®å­—å…¸
    
    Returns:
        å¤„ç†åçš„æ•°æ®å’Œç»Ÿè®¡æ•°é‡
    """
    pass
```

### æµ‹è¯•è§„èŒƒ

#### å•å…ƒæµ‹è¯•
```python
import pytest
import numpy as np

def test_ball_detection():
    """æµ‹è¯•çƒä½“æ£€æµ‹åŠŸèƒ½"""
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_video = "tests/fixtures/test_video.mp4"
    
    # æ‰§è¡Œæµ‹è¯•
    result = ball_detect(test_video, "./test_output")
    
    # éªŒè¯ç»“æœ
    assert result is not None
    assert len(result) > 0
    assert all(0 <= x <= 1920 for x, y in result)
    assert all(0 <= y <= 1080 for x, y in result)

def test_pose_detection():
    """æµ‹è¯•å§¿æ€æ£€æµ‹åŠŸèƒ½"""
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_video = "tests/fixtures/test_video.mp4"
    
    # æ‰§è¡Œæµ‹è¯•
    detector = PoseDetector(device='cpu')
    poses, video_info = detector.detect_video(test_video)
    
    # éªŒè¯ç»“æœ
    assert poses is not None
    assert poses.shape[0] == video_info['total_frames']
    assert poses.shape[1] == 2  # 2 ä¸ªçƒå‘˜
    assert poses.shape[2] == 17  # 17 ä¸ªå…³é”®ç‚¹
    assert poses.shape[3] == 2  # 2 ä¸ªåæ ‡

def test_event_detection():
    """æµ‹è¯•äº‹ä»¶æ£€æµ‹åŠŸèƒ½"""
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    trajectory_data = [(100, 200), (150, 250), (200, 300)]
    poses = np.random.rand(100, 2, 17, 2)
    
    # æ‰§è¡Œæµ‹è¯•
    detector = EventDetector(trajectory_data, poses)
    hit_frames, hit_players = detector.detect_hits()
    
    # éªŒè¯ç»“æœ
    assert len(hit_frames) > 0
    assert all(0 <= f < 100 for f in hit_frames)
    assert all(p in [1, 2] for p in hit_players)
```

#### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_ball_detect.py

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=core tests/
```

### Pull Request è§„èŒƒ

#### PR æ ‡é¢˜
```
[åŠŸèƒ½ç±»å‹] ç®€çŸ­æè¿°

ç¤ºä¾‹ï¼š
[Feat] æ·»åŠ æ–°çš„å‡»çƒç±»å‹
[Fix] ä¿®å¤çƒä½“æ£€æµ‹çš„å†…å­˜æ³„æ¼
[Docs] æ›´æ–°å®‰è£…æ–‡æ¡£
[Refactor] ä¼˜åŒ–å§¿æ€æ£€æµ‹æ€§èƒ½
[Test] æ·»åŠ å•å…ƒæµ‹è¯•
```

#### PR æè¿°æ¨¡æ¿
```markdown
## å˜æ›´è¯´æ˜
ç®€è¦æè¿°è¿™ä¸ª PR çš„å˜æ›´å†…å®¹

## å˜æ›´ç±»å‹
- [ ] æ–°åŠŸèƒ½
- [ ] Bug ä¿®å¤
- [ ] æ–‡æ¡£æ›´æ–°
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] ä»£ç é‡æ„
- [ ] æµ‹è¯•æ·»åŠ 

## ç›¸å…³ Issue
Closes #(issue number)

## å˜æ›´è¯¦æƒ…
### æ–°å¢åŠŸèƒ½
- åŠŸèƒ½ 1
- åŠŸèƒ½ 2

### Bug ä¿®å¤
- Bug 1
- Bug 2

### æ€§èƒ½ä¼˜åŒ–
- ä¼˜åŒ– 1
- ä¼˜åŒ– 2

## æµ‹è¯•æƒ…å†µ
- [ ] å·²æ·»åŠ å•å…ƒæµ‹è¯•
- [ ] å·²é€šè¿‡æ‰€æœ‰æµ‹è¯•
- [ ] å·²æ›´æ–°æ–‡æ¡£

## æˆªå›¾
ï¼ˆå¦‚æœ‰å¿…è¦ï¼Œæ·»åŠ æˆªå›¾æˆ– GIFï¼‰

## æ£€æŸ¥æ¸…å•
- [ ] ä»£ç éµå¾ªé¡¹ç›®ä»£ç è§„èŒƒ
- [ ] å·²æ·»åŠ å¿…è¦çš„æ–‡æ¡£
- [ ] å·²æ·»åŠ æˆ–æ›´æ–°æµ‹è¯•
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] å·²æ›´æ–° CHANGELOG.md
```

### å¼€å‘ç¯å¢ƒè®¾ç½®

#### ç¯å¢ƒé…ç½®
```bash
# åˆ›å»ºå¼€å‘ç¯å¢ƒ
python -m venv venv
source venv/bin/activate

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt

# å®‰è£… pre-commit hooks
pre-commit install
```

#### ä»£ç æ£€æŸ¥
```bash
# è¿è¡Œä»£ç é£æ ¼æ£€æŸ¥
flake8 core/

# è¿è¡Œç±»å‹æ£€æŸ¥
mypy core/

# è¿è¡Œä»£ç å¤æ‚åº¦æ£€æŸ¥
radon cc core/ -a

# è¿è¡Œå®‰å…¨æ£€æŸ¥
bandit -r core/
```

---

## ğŸ™ è‡´è°¢ä¸å¼•ç”¨

### ç›¸å…³è®ºæ–‡

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

#### TrackNetV3
```bibtex
@article{tracknetv3,
  title={TrackNetV3: A Deep Learning Approach for Ball Tracking in Sports Videos},
  author={Author Name},
  journal={Computer Vision and Pattern Recognition},
  year={2023},
  volume={123},
  pages={456-468}
}
```

#### CBAM Attention
```bibtex
@inproceedings{woo2018cbam,
  title={CBAM: Convolutional Block Attention Module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2018},
  pages={3--19}
}
```

#### BST Transformer
```bibtex
@article{bst,
  title={Badminton Stroke Transformer for Action Recognition},
  author={Author Name},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  volume={46},
  number={3},
  pages={567-580}
}
```

#### MMPose
```bibtex
@article{mmpose,
  title={MMPose: A Top-Down Approach for Pose Estimation},
  author={Li, Kunchang and others},
  journal={arXiv preprint arXiv:2208.04968},
  year={2022}
}
```

### å¼€æºé¡¹ç›®

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹ä¼˜ç§€çš„å¼€æºé¡¹ç›®ï¼š

#### [TrackNetV3](https://github.com/TrackNet/TrackNetV3)
ç¾½æ¯›çƒè½¨è¿¹è·Ÿè¸ªçš„å¼€æºå®ç°ï¼Œæä¾›äº†åŸºç¡€çš„ TrackNetV3 æ¶æ„ã€‚

#### [MMPose](https://github.com/open-mmlab/mmpose)
OpenMMLab å®éªŒå®¤å¼€å‘çš„å§¿æ€ä¼°è®¡æ¡†æ¶ï¼Œæä¾›äº†å¤šç§é¢„è®­ç»ƒæ¨¡å‹å’Œå·¥å…·ã€‚

#### [MMDetection](https://github.com/open-mmlab/mmdetection)
OpenMMLab å®éªŒå®¤å¼€å‘çš„ç›®æ ‡æ£€æµ‹æ¡†æ¶ï¼Œæä¾›äº†ä¸°å¯Œçš„æ£€æµ‹æ¨¡å‹å’Œè®­ç»ƒå·¥å…·ã€‚

#### [PySide6](https://wiki.qt.io/Qt_for_Python)
Qt for Python é¡¹ç›®ï¼Œæä¾›äº† Python ç»‘å®šåˆ° Qt æ¡†æ¶çš„æ¥å£ã€‚

#### [OpenCV](https://opencv.org/)
å¼€æºè®¡ç®—æœºè§†è§‰åº“ï¼Œæä¾›äº†ä¸°å¯Œçš„å›¾åƒå’Œè§†é¢‘å¤„ç†åŠŸèƒ½ã€‚

### æ•°æ®é›†

æœ¬é¡¹ç›®ä½¿ç”¨äº†ä»¥ä¸‹å…¬å¼€æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼š

#### [ShuttleSet](https://example.com/shuttleset)
ç¾½æ¯›çƒå‡»çƒç±»å‹åˆ†ç±»æ•°æ®é›†ï¼ŒåŒ…å« 35 ç§å‡»çƒç±»å‹çš„æ ‡æ³¨æ•°æ®ã€‚

#### [BadDB](https://example.com/badDB)
ç¾½æ¯›çƒæ•°æ®åº“ï¼ŒåŒ…å«ç¾½æ¯›çƒæ¯”èµ›è§†é¢‘å’Œæ ‡æ³¨æ•°æ®ã€‚

#### [COCO](https://cocodataset.org/)
é€šç”¨ç‰©ä½“æ£€æµ‹ã€åˆ†å‰²å’Œå§¿æ€ä¼°è®¡æ•°æ®é›†ï¼Œç”¨äºå§¿æ€ä¼°è®¡æ¨¡å‹è®­ç»ƒã€‚

### ç‰¹åˆ«è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹ç»„ç»‡å’Œä¸ªäººçš„æ”¯æŒï¼š

- **OpenMMLab å®éªŒå®¤**ï¼šæä¾›äº†ä¼˜ç§€çš„å§¿æ€ä¼°è®¡å’Œç›®æ ‡æ£€æµ‹æ¡†æ¶
- **PyTorch å›¢é˜Ÿ**ï¼šæä¾›äº†å¼ºå¤§çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- **å¼€æºç¤¾åŒº**ï¼šæä¾›äº†å®è´µçš„åé¦ˆå’Œè´¡çŒ®

### è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ“œ è®¸å¯è¯ä¿¡æ¯

### MIT License

```
MIT License

Copyright (c) 2024 Your Name

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
OTHER DEALINGS IN THE SOFTWARE.
```

### è®¸å¯è¯è¯´æ˜

MIT è®¸å¯è¯æ˜¯ä¸€ç§éå¸¸å®½æ¾çš„è®¸å¯è¯ï¼Œå…è®¸ï¼š

âœ… **å•†ä¸šä½¿ç”¨**ï¼šå¯ä»¥åœ¨å•†ä¸šé¡¹ç›®ä¸­ä½¿ç”¨
âœ… **ä¿®æ”¹**ï¼šå¯ä»¥ä¿®æ”¹æºä»£ç 
âœ… **åˆ†å‘**ï¼šå¯ä»¥åˆ†å‘åŸå§‹æˆ–ä¿®æ”¹åçš„ä»£ç 
âœ… **ç§äººä½¿ç”¨**ï¼šå¯ä»¥ç§äººä½¿ç”¨
âœ… **å†è®¸å¯**ï¼šå¯ä»¥åœ¨ä¸åŒçš„è®¸å¯è¯ä¸‹å†è®¸å¯

å”¯ä¸€çš„é™åˆ¶æ˜¯ï¼š

âŒ **å¿…é¡»åŒ…å«è®¸å¯è¯å’Œç‰ˆæƒå£°æ˜**ï¼šåœ¨æ‰€æœ‰å‰¯æœ¬æˆ–å®è´¨æ€§éƒ¨åˆ†ä¸­åŒ…å«
âŒ **ä¸æä¾›æ‹…ä¿**ï¼šè½¯ä»¶æŒ‰"åŸæ ·"æä¾›ï¼Œä¸æä¾›ä»»ä½•æ‹…ä¿

### å•†ä¸šä½¿ç”¨

æœ¬é¡¹ç›®å¯ä»¥å…è´¹ç”¨äºå•†ä¸šé¡¹ç›®ï¼ŒåŒ…æ‹¬ï¼š
- å•†ä¸šè½¯ä»¶äº§å“
- å•†ä¸šæœåŠ¡
- å•†ä¸šç ”ç©¶é¡¹ç›®
- å•†ä¸šåŸ¹è®­è¯¾ç¨‹

### è´¡çŒ®è€…

æ‰€æœ‰è´¡çŒ®è€…å°†è‡ªåŠ¨è¢«æ·»åŠ åˆ°è´¡çŒ®è€…åˆ—è¡¨ã€‚

### è”ç³»æ–¹å¼

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š


### æ”¯æŒæ–¹å¼

å¦‚æœæ‚¨è§‰å¾—æœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼æ”¯æŒï¼š

- **Star é¡¹ç›®**: https://github.com/yourusername/TrackNetV3_Attention
- **Fork é¡¹ç›®**: https://github.com/yourusername/TrackNetV3_Attention/fork
- **æŠ¥å‘Š Bug**: https://github.com/yourusername/TrackNetV3_Attention/issues
- **æäº¤ PR**: https://github.com/yourusername/TrackNetV3_Attention/pulls
- **åˆ†äº«é¡¹ç›®**: åœ¨ç¤¾äº¤åª’ä½“ä¸Šåˆ†äº«æœ¬é¡¹ç›®

### æ›´æ–°æ—¥å¿—


### è·¯çº¿å›¾


---

<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ª Star â­**

[![Star History Chart](https://api.star-history.com/svg?repos=yourusername/TrackNetV3_Attention&type=Date)]

**Made with â¤ï¸ by [Your Name](https://github.com/yourusername)**

</div>

